{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75852f7a-df87-47a9-8202-3bd96686d672",
   "metadata": {},
   "source": [
    "## Environment/Import/Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4794f8e-3201-41dd-bac0-2d9eabe6e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Python interpreter the notebook is using (for debug)\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc00059-f508-4602-8152-e3d6ef0525c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Pandas to avoid future warnings\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a4da6-b7ea-4d4f-ba47-721254119fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put down some non-critical warnings to keep the notebook output clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a5e6c-c6a7-4491-adbb-d38eb3dbbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Matplotlib to show  plots inside the notebook, below the code \n",
    "import matplotlib\n",
    "matplotlib.use('module://matplotlib_inline.backend_inline')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a01e3-97cb-487e-9336-e2a1cddd36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages to see if everything is installed and works\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl import statsbomb as spadl\n",
    "from socceraction.vaep import features, labels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e79c3-b5cb-442a-ba19-b079555f2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas to display all columns and rows\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None)     \n",
    "pd.set_option('display.width', None)        \n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38420b-4fa1-4290-ba06-d5fc52bd476b",
   "metadata": {},
   "source": [
    "## The 19 playing styles adapted (Best performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807c49d-c2ac-4e68-9be5-a93b197afc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries used in the code\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import plotly.express as px\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl import statsbomb as spadl_sb\n",
    "from socceraction import spadl\n",
    "from socceraction.vaep import features as feat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "#Load StatsBomb data locally\n",
    "sbl = StatsBombLoader(\n",
    "    getter=\"local\",  # from local files\n",
    "    root=\"C:/Users/helio/MachineLearning/Bachelor/statsbomb_data/open-data-master/data\"\n",
    ")\n",
    "\n",
    "# Get all games for a given competition and season\n",
    "# Competition ID = 2, Season ID = 27 (Premier League 2015/16)\n",
    "# Competition ID = 11, Season ID = 27 (La Liga 2015/16)\n",
    "# Competition ID = 9, Season ID = 27 (Bundesliga 2015/16)\n",
    "# Competition ID = 12, Season ID = 27 (Serie A 2015/16)\n",
    "# Competition ID = 7, Season ID = 27 (Ligue 1 2015/16)\n",
    "games = sbl.games(2, 27)\n",
    "\n",
    "# Load pre-trained VAEP model that some metrics need, especially VAEP metrics\n",
    "data = joblib.load(\"C:/Users/helio/MachineLearning/Bachelor/vaep_model_xgboost_5leagues_1516.pkl\")\n",
    "# The trained model\n",
    "model = data[\"model\"]          \n",
    "# Expected input features for model\n",
    "expected_columns = data[\"feature_columns\"] \n",
    "\n",
    "\n",
    "# Create a mapping of team ids to names for all matches of interest\n",
    "matches_of_interest = games[[\"game_id\", \"home_team_id\", \"away_team_id\"]].copy()\n",
    "team_id_name_map = {}\n",
    "for game_id in matches_of_interest[\"game_id\"]:\n",
    "    teams = sbl.teams(game_id)\n",
    "    for _, row in teams.iterrows():\n",
    "        team_id_name_map[row[\"team_id\"]] = row[\"team_name\"]\n",
    "\n",
    "# Add team names to match dataframe\n",
    "matches_of_interest[\"home_team_name\"] = matches_of_interest[\"home_team_id\"].map(team_id_name_map)\n",
    "matches_of_interest[\"away_team_name\"] = matches_of_interest[\"away_team_id\"].map(team_id_name_map)\n",
    "\n",
    "# Keep only rows with valid team names\n",
    "matches_of_interest = matches_of_interest.dropna(subset=[\"home_team_name\", \"away_team_name\"])\n",
    "\n",
    "\n",
    "# compute team metrics for a single match\n",
    "def evaluate_team_metrics(game_id, home_name, away_name, model):\n",
    "    # Load game and prepare base dataframe\n",
    "    match = games.loc[games[\"game_id\"] == game_id].iloc[0]\n",
    "    home_id, away_id = match[\"home_team_id\"], match[\"away_team_id\"]\n",
    "    events = sbl.events(game_id)\n",
    "    # convert to SPADL actions\n",
    "    actions = spadl.add_names(spadl_sb.convert_to_actions(events, home_id))\n",
    "    df = pd.DataFrame(index=[home_id, away_id])\n",
    "\n",
    "    # Predict VAEP for each action (for VAEP metrics only)\n",
    "    gamestates = feat.play_left_to_right(feat.gamestates(actions, nb_prev_actions=3), home_id)\n",
    "    X = pd.concat([f(gamestates) for f in [\n",
    "        feat.actiontype_onehot, feat.result_onehot, feat.bodypart_onehot,\n",
    "        feat.startlocation, feat.endlocation, feat.movement, feat.time\n",
    "    ]], axis=1)\n",
    "    # Ensure all expected model columns are present\n",
    "    for col in expected_columns:\n",
    "        if col not in X.columns:\n",
    "            X[col] = 0\n",
    "    X = X[expected_columns]\n",
    "    actions[\"vaep_pred\"] = model.predict(X)\n",
    "\n",
    "    # Events enrichements , adding basic info to each action\n",
    "    # time since previous action\n",
    "    actions[\"time_diff\"] = actions[\"time_seconds\"].diff().fillna(0)\n",
    "    # movement distance of the ball\n",
    "    actions[\"distance\"] = np.sqrt((actions['end_x'] - actions['start_x'])**2 + (actions['end_y'] - actions['start_y'])**2)\n",
    "\n",
    "    # Select defensive actions (tackle, interception, clearance)\n",
    "    defensive = actions[actions[\"type_name\"].isin([\"interception\", \"tackle\", \"clearance\"])]\n",
    "\n",
    "    # Identify crosses using event data\n",
    "    events_flat = pd.json_normalize(events.to_dict(orient=\"records\"), sep=\"_\")\n",
    "    passes_events = events_flat[events_flat[\"type_name\"] == \"Pass\"]\n",
    "    cross_events = passes_events[passes_events.get(\"extra_pass_cross\", False) == True]\n",
    "\n",
    "    # Define possessions\n",
    "    actions = actions.sort_values(['team_id', 'period_id', 'time_seconds'])\n",
    "    actions['possession_id'] = actions.groupby((actions['time_seconds'].diff() > 10).cumsum()).ngroup()\n",
    "    actions['possession_time'] = actions.groupby(['team_id', 'possession_id'])['time_diff'].transform('sum')\n",
    "\n",
    "    # Total number of actions per team (will be used in some metrics to improve them)\n",
    "    total_actions = actions.groupby('team_id').size()\n",
    "\n",
    "    # Ball regains\n",
    "    regains = actions[actions['type_name'].isin(['interception', 'tackle', 'clearance'])]\n",
    "\n",
    "    # Build-up speed , total distance moved per second of play\n",
    "    if 'time_seconds' in actions.columns:\n",
    "     actions['time_diff'] = actions.groupby(['team_id'])['time_seconds'].diff().fillna(0)\n",
    "     df['BuildUpSpeed'] = actions.groupby('team_id')['distance'].sum() / actions.groupby('team_id')['time_diff'].sum()\n",
    "\n",
    "    # Count aerial challenges (headed actions)\n",
    "    df['AerialChallenges'] = actions[actions['bodypart_name'] == 'head'].groupby('team_id').size()\n",
    "\n",
    "    # Initialize counters for counterattack metric\n",
    "    counterattack_vaep = {home_id: 0, away_id: 0}\n",
    "    counterattack_count = {home_id: 0, away_id: 0}\n",
    "    opponent_counterattacks = {home_id: 0, away_id: 0}\n",
    "    # Parameters for detecting counterattacks\n",
    "    DEFENSIVE_ACTIONS = ['interception', 'tackle', 'clearance', 'keeper_save']\n",
    "    MIN_PROGRESSION = 15  # meters of forward movement\n",
    "    MAX_TIME_WINDOW = 10  # seconds\n",
    "    MAX_ACTIONS_TO_CHECK = 5  # actions to examine\n",
    "    \n",
    "    # Detect counterattacks\n",
    "    for idx, row in actions.iterrows():\n",
    "        if row['type_name'] in DEFENSIVE_ACTIONS:\n",
    "        \n",
    "            team = row['team_id']\n",
    "            opponent = home_id if team == away_id else away_id\n",
    "            start_time = row['time_seconds']\n",
    "            start_x = row['start_x']\n",
    "            vaep_sum = 0\n",
    "            max_progression = 0\n",
    "            valid_counterattack = False\n",
    "        \n",
    "            # Check actions\n",
    "            for i in range(1, MAX_ACTIONS_TO_CHECK + 1):\n",
    "                if idx + i >= len(actions):\n",
    "                    break\n",
    "                \n",
    "                next_row = actions.iloc[idx + i]\n",
    "            \n",
    "                # Break if possession changes or time window expires\n",
    "                if next_row['team_id'] != team or (next_row['time_seconds'] - start_time) > MAX_TIME_WINDOW:\n",
    "                    break\n",
    "                \n",
    "                # Track total VAEP value in the sequence\n",
    "                vaep_sum += next_row['vaep_pred']\n",
    "            \n",
    "                # Track maximum progression achieved\n",
    "                current_progression = next_row['end_x'] - start_x\n",
    "                if current_progression > max_progression:\n",
    "                    max_progression = current_progression\n",
    "            \n",
    "                # Early exit if we already have sufficient progression\n",
    "                if max_progression >= MIN_PROGRESSION:\n",
    "                    valid_counterattack = True\n",
    "\n",
    "            \n",
    "            # Register if we achieved minimum progression and positive VAEP\n",
    "            if valid_counterattack and vaep_sum > 0:\n",
    "                counterattack_vaep[team] += vaep_sum\n",
    "                counterattack_count[team] += 1\n",
    "                opponent_counterattacks[opponent] += 1\n",
    "\n",
    "    # Save counterattack metrics, one for the team and one for the opponent\n",
    "    df['CounterattackIndex'] = pd.Series(counterattack_vaep) / pd.Series(counterattack_count)\n",
    "    OppCounterAttacks = pd.Series(opponent_counterattacks)\n",
    "    defensiveCounterAttack = actions[actions[\"type_name\"].isin([\"interception\", \"tackle\", \"clearance\"])].groupby('team_id').size()\n",
    "    df['OppCounterAttackRate'] = OppCounterAttacks / defensiveCounterAttack\n",
    "\n",
    "    # Defensive block compactness\n",
    "    def_actions = actions[actions['type_name'].isin(['tackle', 'interception', 'clearance'])]\n",
    "    def_total = def_actions.groupby('team_id').size()\n",
    "    def_low = def_actions[def_actions['start_x'] <= 33.3].groupby('team_id').size()\n",
    "    df['LowBlockRatio'] = def_low / def_total\n",
    "\n",
    "    # Quick regains in middle third (preventing opponent counters)\n",
    "    actions['team_change'] = actions['team_id'] != actions['team_id'].shift(1)\n",
    "    actions['next_action_time'] = actions['time_seconds'].shift(-1)\n",
    "    actions['time_to_next'] = actions['next_action_time'] - actions['time_seconds']\n",
    "    quick_regains = actions[\n",
    "        (actions['type_name'].isin(['interception', 'tackle'])) &\n",
    "        (actions['start_x'] >= 33.3) & (actions['start_x'] <= 66.7) &\n",
    "        (actions['time_to_next'] <= 5)  # quick regain after loss\n",
    "    ]\n",
    "    df['PreventedCounters_Mid3'] = quick_regains.groupby('team_id').size() / actions.groupby('team_id').size()\n",
    "\n",
    "    # Count the number of crosses\n",
    "    df[\"Crosses\"] = cross_events.groupby(\"team_id\").size()\n",
    "\n",
    "    # Opponent attack types\n",
    "    opponent_actions = actions.copy()\n",
    "    df['OppOpenPlayRatio'] = opponent_actions[\n",
    "        opponent_actions['type_name'].isin(['pass', 'dribble'])\n",
    "    ].groupby('team_id').size() / opponent_actions.groupby('team_id').size()\n",
    "    df['OppSetPieceRatio'] = opponent_actions[\n",
    "        opponent_actions['type_name'].isin(['corner_crossed', 'freekick_crossed', 'freekick_short', 'throw_in'])\n",
    "    ].groupby('team_id').size() / opponent_actions.groupby('team_id').size()\n",
    "\n",
    "    # Where regains of the ball occur on the pitch (average X location)\n",
    "    df['AvgDefensiveRegainX'] = regains.groupby('team_id')['start_x'].mean()\n",
    "\n",
    "    # Pressing intensity (PPDA)\n",
    "    passes = actions[actions['type_name'] == 'pass']\n",
    "    defensive_actions = actions[\n",
    "        (actions['type_name'].isin(['tackle', 'interception', 'clearance'])) & \n",
    "        (actions['start_x'] >= 40)\n",
    "    ]\n",
    "    ppda_n = passes.groupby('team_id').size()\n",
    "    ppda_d = defensive_actions.groupby('team_id').size()\n",
    "    df['PPDA'] = ppda_n / ppda_d\n",
    "\n",
    "    # Defensive activity count\n",
    "    df[\"DefensiveActions\"] = defensive.groupby(\"team_id\").size()\n",
    "\n",
    "    # Play orientation indices\n",
    "    df['CentralPlayIndex'] = actions[(actions['start_y'].between(30, 50))].groupby('team_id')['vaep_pred'].sum() / total_actions\n",
    "    df['WingPlayIndex'] = actions[(actions['start_y'] < 20) | (actions['start_y'] > 60)].groupby('team_id')['vaep_pred'].sum() / total_actions\n",
    "\n",
    "    # Dribble frequency\n",
    "    df['Dribbles'] = actions[actions['type_name'] == 'dribble'].groupby('team_id').size() / actions.groupby('team_id').size()\n",
    "\n",
    "    # Average time between a team’s actions\n",
    "    df['TimePerAction'] = actions.groupby('team_id')['time_diff'].mean()\n",
    "\n",
    "    # Lost balls via failed passes or dribbles\n",
    "    lost_passes = actions[\n",
    "        (actions['type_name'] == 'pass') & \n",
    "        (actions['result_name'] == 'fail')\n",
    "    ]\n",
    "    lost_dribbles = actions[\n",
    "        (actions['type_name'].isin(['dribble', 'take_on'])) & \n",
    "        (actions['result_name'] == 'fail')\n",
    "    ]\n",
    "    # Combine and count\n",
    "    lost_balls = pd.concat([lost_passes, lost_dribbles])\n",
    "    df['LostBalls'] = lost_balls.groupby('team_id').size()\n",
    "\n",
    "    # Defensive recoveries inside own half\n",
    "    df['Recoveries_OwnHalf'] = actions[\n",
    "        (actions['type_name'].isin(['interception', 'tackle', 'clearance'])) & \n",
    "        (actions['start_x'] < 50)\n",
    "    ].groupby('team_id').size()\n",
    "\n",
    "    # Fouls and yellow cards\n",
    "    df['Fouls'] = actions[actions['type_name'] == 'foul'].groupby('team_id').size() / actions.groupby('team_id').size()\n",
    "    if \"extra_foul_committed_card_name\" in events_flat.columns:\n",
    "        carded_fouls = events_flat[\n",
    "            events_flat[\"extra_foul_committed_card_name\"].isin([\"Yellow Card\", \"Red Card\"])\n",
    "        ]\n",
    "        card_counts = carded_fouls.groupby([\"team_id\", \"extra_foul_committed_card_name\"]).size().unstack(fill_value=0)\n",
    "        total_team_actions = actions.groupby(\"team_id\").size()\n",
    "        df[\"YellowCards\"] = card_counts.get(\"Yellow Card\", 0) / total_team_actions\n",
    "\n",
    "    else:\n",
    "        # if no yellow cards in the game\n",
    "        df[\"YellowCards\"] = 0\n",
    "\n",
    "\n",
    "    # Creating Final Attempts (Little vs High Possession Needed)\n",
    "    possesion_count = actions.groupby('team_id')['possession_id'].nunique()\n",
    "    total_shots = actions[actions['type_name'] == 'shot'].groupby('team_id').size()\n",
    "    df['FinalAttemptCreation'] = (total_shots / possesion_count.fillna(0))\n",
    "\n",
    "    # Type of Attack (Set Pieces vs Open Play)\n",
    "    set_piece_actions = actions[actions['type_name'].isin([\n",
    "        'freekick_crossed', 'freekick_short', 'corner_crossed', 'corner_short'\n",
    "    ])]\n",
    "    set_piece_count = set_piece_actions.groupby('team_id').size()\n",
    "    total_attacks = actions[actions['type_name'].isin(['pass', 'dribble', 'shot'])].groupby('team_id').size()\n",
    "    df['SetPieceAttackRate'] = (set_piece_count / total_attacks).fillna(0)\n",
    "\n",
    "    # Effective playing time (time when ball in play, ignoring >10s breaks)\n",
    "    actions = actions.sort_values(['team_id', 'period_id', 'time_seconds'])\n",
    "    actions['time_diff'] = actions.groupby(['team_id', 'period_id'])['time_seconds'].diff().fillna(0)\n",
    "    actions['valid_play'] = actions['time_diff'] <= 10\n",
    "    df['EffectiveTime'] = actions[actions['valid_play']].groupby('team_id')['time_diff'].sum()\n",
    "\n",
    "    # fill missing values with 0\n",
    "    df = df.fillna(0)\n",
    "    # replace team ids with team names\n",
    "    df.index = df.index.map(lambda x: home_name if x == home_id else away_name)\n",
    "    return df\n",
    "\n",
    "# store cumulative metrics for all teams\n",
    "team_vaep_metrics = {}\n",
    "\n",
    "# loop through each match\n",
    "for _, row in tqdm(matches_of_interest.iterrows(), total=len(matches_of_interest)):\n",
    "    game_id = row[\"game_id\"]\n",
    "    home_name = row[\"home_team_name\"]\n",
    "    away_name = row[\"away_team_name\"]\n",
    "\n",
    "    # get metrics for this match\n",
    "    df = evaluate_team_metrics(game_id, home_name, away_name, model)\n",
    "\n",
    "    # add metrics to each team (sum over matches)\n",
    "    for team in df.index:\n",
    "        if team not in team_vaep_metrics:\n",
    "            team_vaep_metrics[team] = df.loc[team]  # first time just add\n",
    "        else:\n",
    "            team_vaep_metrics[team] += df.loc[team] # otherwise sum up\n",
    "\n",
    "# convert dictionary to DataFrame for readability\n",
    "df_stocked = pd.DataFrame(team_vaep_metrics).T.fillna(0)\n",
    "print(\"Data available in df_stocked\")\n",
    "print(df_stocked)\n",
    "\n",
    "\n",
    "def apply_pca_transformation(df_stocked, n_components=None, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to create latent tactical style components\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\" PCA-BASED TACTICAL STYLE TRANSFORMATION\")\n",
    "    \n",
    "    # prepare data\n",
    "    X = df_stocked.copy()\n",
    "    # make sure to have only one team and no duplicates\n",
    "    X = X.loc[~X.index.duplicated(keep='first')]\n",
    "\n",
    "    # CORRELATION ANALYSIS\n",
    "    print(\"\\n CORRELATION ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    # find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    print(f\"Highly correlated pairs (>0.7): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"   {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "    \n",
    "    # STANDARDIZATION\n",
    "    print(\"\\n DATA STANDARDIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\" Data standardized (mean=0, std=1)\")\n",
    "    \n",
    "    # PCA APPLICATION\n",
    "    print(\"\\n PCA APPLICATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # apply PCA with all components first to analyze variance\n",
    "    pca_full = PCA()\n",
    "    X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "    \n",
    "    # calculate cumulative variance\n",
    "    added_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    # determine the number of components\n",
    "    if n_components is None:\n",
    "        n_components = np.argmax(added_variance >= variance_threshold) + 1\n",
    "        print(f\"Components needed for {variance_threshold*100}% variance: {n_components}\")\n",
    "    \n",
    "    # apply PCA with the chosen number of components\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Final PCA shape: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Cumulative variance explained: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "    \n",
    "    # component interpretation\n",
    "    print(\"\\n TACTICAL STYLE COMPONENTS INTERPRETATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # create component interpretation\n",
    "    components_df = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.columns\n",
    "    )\n",
    "    \n",
    "    # interpret each component\n",
    "    tactical_styles = {}\n",
    "    for i in range(n_components):\n",
    "        component_name = f'Style_{i+1}'\n",
    "        component_loadings = components_df[component_name].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\n {component_name} (explains {pca.explained_variance_ratio_[i]:.1%} variance):\")\n",
    "        \n",
    "        # top positive loadings\n",
    "        pos_loadings = components_df[component_name].sort_values(ascending=False).head(3)\n",
    "        print(\"   Top positive loadings:\")\n",
    "        for feat, loading in pos_loadings.items():\n",
    "            print(f\"      +{loading:.3f} {feat}\")\n",
    "        \n",
    "        # top negative loadings\n",
    "        neg_loadings = components_df[component_name].sort_values(ascending=True).head(3)\n",
    "        print(\"   Top negative loadings:\")\n",
    "        for feat, loading in neg_loadings.items():\n",
    "            print(f\"      {loading:.3f} {feat}\")\n",
    "        \n",
    "        # suggest a tactical interpretation\n",
    "        top_features = component_loadings.head(3).index.tolist()\n",
    "        tactical_styles[component_name] = {\n",
    "            'variance_explained': pca.explained_variance_ratio_[i],\n",
    "            'top_features': top_features\n",
    "        }\n",
    "    \n",
    "    # Create a PCA dataFrame for visibility and better understandings\n",
    "    pca_df = pd.DataFrame(\n",
    "        X_pca, \n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'pca_df': pca_df,\n",
    "        'pca_model': pca,\n",
    "        'scaler': scaler,\n",
    "        'components_df': components_df,\n",
    "        'tactical_styles': tactical_styles,\n",
    "        'original_data': X,\n",
    "        'scaled_data': X_scaled,\n",
    "        'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "        'added_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "    }\n",
    "\n",
    "def cluster_pca_styles(pca_results, clustering_methods=None, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Apply clustering to PCA-transformed tactical styles\n",
    "    \"\"\"\n",
    "    # The 5 clustering algorithms\n",
    "    if clustering_methods is None:\n",
    "        clustering_methods = {\n",
    "            \"KMeans\": {\"n_clusters\": 9},\n",
    "            \"Agglomerative\": {\"n_clusters\": 9},\n",
    "            \"GMM\": {\"n_components\": 9},\n",
    "            \"Spectral\": {\"n_clusters\": 9},\n",
    "            \"Birch\": {\"n_clusters\": 6}\n",
    "        }\n",
    "    \n",
    "\n",
    "    # Extract the PCA-transformed feature matrix (scores) from results\n",
    "    # Get PCA scores as a NumPy array for clustering\n",
    "    pca_df = pca_results['pca_df']\n",
    "    X_pca = pca_df.values\n",
    "    \n",
    "    # standardize PCA components\n",
    "    scaler_pca = StandardScaler()\n",
    "    X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
    "\n",
    "\n",
    "    print(\"\\n OPTIMAL NUMBER OF CLUSTERS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Test different numbers of clusters\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    # metrics for different clustering algorithms\n",
    "    metrics = {\n",
    "        'KMeans': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Agglomerative': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'GMM': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Birch': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Spectral': {'silhouette': [], 'calinski': [], 'davies': []}\n",
    "    }\n",
    "\n",
    "    # Try different numbers of clusters for each algorithm and record quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    for n_clusters in cluster_range:\n",
    "        \n",
    "        # KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels_km = kmeans.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Agglomerative\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        labels_agg = agg.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # GMM\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        labels_gmm = gmm.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Birch \n",
    "        birch = Birch(n_clusters=n_clusters)\n",
    "        labels_birch = birch.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Spectral\n",
    "        try:\n",
    "            spectral = SpectralClustering(n_clusters=n_clusters, random_state=42, affinity='nearest_neighbors')\n",
    "            labels_spectral = spectral.fit_predict(X_pca_scaled)\n",
    "        except Exception as e:\n",
    "            print(f\"  Spectral clustering failed for {n_clusters} clusters: {e}\")\n",
    "            # créer des labels par défaut en cas d'échec\n",
    "            labels_spectral = np.zeros(len(X_pca_scaled), dtype=int)\n",
    "        \n",
    "        # calculate metrics \n",
    "        for name, labels in [('KMeans', labels_km), ('Agglomerative', labels_agg), \n",
    "                           ('GMM', labels_gmm), ('Birch', labels_birch), ('Spectral', labels_spectral)]:\n",
    "            if len(np.unique(labels)) > 1:  # Need at least 2 clusters for metrics (For 2D vizualisation)\n",
    "                try:\n",
    "                    metrics[name]['silhouette'].append(silhouette_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['calinski'].append(calinski_harabasz_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['davies'].append(davies_bouldin_score(X_pca_scaled, labels))\n",
    "                except Exception as e:\n",
    "                    print(f\"   Error calculating metrics for {name} with {n_clusters} clusters: {e}\")\n",
    "                    metrics[name]['silhouette'].append(0)\n",
    "                    metrics[name]['calinski'].append(0)\n",
    "                    metrics[name]['davies'].append(float('inf'))\n",
    "            else:\n",
    "                metrics[name]['silhouette'].append(0)\n",
    "                metrics[name]['calinski'].append(0)\n",
    "                metrics[name]['davies'].append(float('inf'))\n",
    "\n",
    "    # print optimal number of clusters\n",
    "    print(\"Optimal number of clusters by metric:\")\n",
    "    for algorithm in metrics.keys():\n",
    "        if metrics[algorithm]['silhouette']:\n",
    "            try:\n",
    "                best_sil = cluster_range[np.argmax(metrics[algorithm]['silhouette'])]\n",
    "                best_cal = cluster_range[np.argmax(metrics[algorithm]['calinski'])]\n",
    "                best_dav = cluster_range[np.argmin(metrics[algorithm]['davies'])]\n",
    "                print(f\"   {algorithm:>12}: Silhouette={best_sil}, Calinski={best_cal}, Davies-Bouldin={best_dav}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   {algorithm:>12}: Error calculating optimal clusters - {e}\")\n",
    "\n",
    "    # Print the full score table per algorithm\n",
    "    print(\"\\n Full clustering scores by number of clusters:\")\n",
    "    for algorithm in metrics:\n",
    "        print(f\"\\n {algorithm}\")\n",
    "        print(\"Clusters | Silhouette | Calinski-Harabasz | Davies-Bouldin\")\n",
    "        for i, n in enumerate(cluster_range):\n",
    "            if i < len(metrics[algorithm]['silhouette']):\n",
    "                sil = metrics[algorithm]['silhouette'][i]\n",
    "                cal = metrics[algorithm]['calinski'][i]\n",
    "                dav = metrics[algorithm]['davies'][i]\n",
    "                print(f\"{n:>8} | {sil:>10.3f} | {cal:>18.2f} | {dav:>15.3f}\")\n",
    "    \n",
    "    clustering_results = {}\n",
    "\n",
    "    # Fit each clustering algorithm with its chosen parameters on the PCA data\n",
    "    # compute quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    # store the results and print the composition of each cluster.\n",
    "    for method_name, params in clustering_methods.items():\n",
    "        print(f\"\\n {method_name} Clustering\")\n",
    "        \n",
    "        try:\n",
    "            if method_name == \"KMeans\":\n",
    "                model = KMeans(random_state=42, n_init=10, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Agglomerative\":\n",
    "                model = AgglomerativeClustering(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"GMM\":\n",
    "                model = GaussianMixture(random_state=42, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Spectral\":\n",
    "                model = SpectralClustering(random_state=42, affinity='nearest_neighbors', **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Birch\":  \n",
    "                model = Birch(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "            \n",
    "            # evaluate clustering quality\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                sil_score = silhouette_score(X_pca_scaled, labels)\n",
    "                cal_score = calinski_harabasz_score(X_pca_scaled, labels)\n",
    "                dav_score = davies_bouldin_score(X_pca_scaled, labels)\n",
    "                \n",
    "                print(f\"   Silhouette Score: {sil_score:.3f}\")\n",
    "                print(f\"   Calinski-Harabasz: {cal_score:.2f}\")\n",
    "                print(f\"   Davies-Bouldin: {dav_score:.3f}\")\n",
    "                \n",
    "                clustering_results[method_name] = {\n",
    "                    'labels': labels,\n",
    "                    'model': model,\n",
    "                    'silhouette': sil_score,\n",
    "                    'calinski': cal_score,\n",
    "                    'davies_bouldin': dav_score\n",
    "                }\n",
    "                \n",
    "                # Print cluster composition\n",
    "                print(f\"   Cluster composition:\")\n",
    "                for cluster_id in np.unique(labels):\n",
    "                    cluster_teams = pca_df.index[labels == cluster_id].tolist()\n",
    "                    print(f\"      Cluster {cluster_id}: {cluster_teams}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\" Error with {method_name}: {e}\")\n",
    "    \n",
    "    return clustering_results\n",
    "\n",
    "\n",
    "def visualize_pca_clusters(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Visualize clustering results on PCA space\n",
    "    \"\"\"\n",
    "    print(\"\\n CLUSTERING VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    #Extract PCA scores (teams and components) and variance ratios for labeling axes\n",
    "    pca_df = pca_results['pca_df']\n",
    "    explained_variance = pca_results['explained_variance_ratio']\n",
    "    \n",
    "    # create a visualization for each clustering method\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        sil_score = result['silhouette']\n",
    "        \n",
    "        # create plot dataframe\n",
    "        plot_df = pca_df.copy()\n",
    "        plot_df['Team'] = plot_df.index\n",
    "        plot_df['Cluster'] = labels.astype(str)\n",
    "        \n",
    "        # 2D visualization for first two components\n",
    "        if pca_df.shape[1] >= 2:\n",
    "            fig = px.scatter(\n",
    "                plot_df, x='Style_1', y='Style_2',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering on Tactical Styles',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})'},\n",
    "                width=1000, height=600\n",
    "            )\n",
    "            fig.update_traces(textposition='top center')\n",
    "            fig.show()\n",
    "        \n",
    "        # 3D visualization if we have at least 3 components\n",
    "        if pca_df.shape[1] >= 3:\n",
    "            fig = px.scatter_3d(\n",
    "                plot_df, x='Style_1', y='Style_2', z='Style_3',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering - 3D Tactical Space',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})',\n",
    "                       'Style_3': f'Style 3 ({explained_variance[2]:.1%})'},\n",
    "                width=1000, height=700\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "def compute_global_discriminant_features(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Compute average F-ratio (feature importance) across all clustering methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n GLOBAL MOST DISCRIMINANT FEATURES (FOR ALL CLUSTERINGS)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Prepare a dictionary to store F-ratios per feature for each clustering method\n",
    "    original_data = pca_results['original_data']\n",
    "    global_f_ratios = {feature: [] for feature in original_data.columns}\n",
    "\n",
    "    # Loop over results from each clustering algorithm\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        original_with_clusters = original_data.copy()\n",
    "        original_with_clusters['Cluster'] = labels\n",
    "        unique_clusters = np.unique(labels)\n",
    "\n",
    "        #Loop through every original metric (feature)\n",
    "        for feature in original_data.columns:\n",
    "            feature_values = original_with_clusters[feature].values\n",
    "            overall_mean = np.mean(feature_values)\n",
    "\n",
    "            between_ss = 0\n",
    "            within_ss = 0\n",
    "\n",
    "            # Loop through each cluster to accumulate between/within variance\n",
    "            for cluster_id in unique_clusters:\n",
    "                cluster_vals = original_with_clusters[original_with_clusters['Cluster'] == cluster_id][feature].values\n",
    "                cluster_mean = np.mean(cluster_vals)\n",
    "                between_ss += len(cluster_vals) * (cluster_mean - overall_mean) ** 2\n",
    "                within_ss += np.sum((cluster_vals - cluster_mean) ** 2)\n",
    "\n",
    "            # Compute the F-ratio: higher means the feature better separates clusters\n",
    "            f_ratio = between_ss / within_ss if within_ss > 0 else 0\n",
    "            # Save this F-ratio for the current feature and clustering method\n",
    "            global_f_ratios[feature].append(f_ratio)\n",
    "\n",
    "    # average F-ratios across algorithms\n",
    "    avg_f_ratios = [(feature, np.mean(f_vals)) for feature, f_vals in global_f_ratios.items()]\n",
    "    avg_f_ratios.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\" Averaged most discriminating features across clustering methods:\")\n",
    "    for i, (feature, avg_f) in enumerate(avg_f_ratios):\n",
    "        print(f\"   {i+1:2d}. {feature:<25} Avg F-ratio = {avg_f:.3f}\")\n",
    "\n",
    "    # main execution function\n",
    "def run_pca_tactical_analysis(df_stocked):\n",
    "    \"\"\"\n",
    "    Run a complete PCA-based tactical analysis\n",
    "    \"\"\"\n",
    "    # 1: Apply PCA transformation\n",
    "    pca_results = apply_pca_transformation(df_stocked, variance_threshold=0.85)\n",
    "    \n",
    "    # 2: Apply clustering to PCA components\n",
    "    clustering_results = cluster_pca_styles(pca_results, max_clusters=9)\n",
    "    \n",
    "    # 3: Visualize clustering results\n",
    "    visualize_pca_clusters(pca_results, clustering_results)\n",
    "\n",
    "    # 4: Compute global discriminant features across all clusterings\n",
    "    compute_global_discriminant_features(pca_results, clustering_results)\n",
    "\n",
    "    #Return results for further analysis\n",
    "    return {\n",
    "        'pca_results': pca_results,\n",
    "        'clustering_results': clustering_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Run main function\n",
    "results = run_pca_tactical_analysis(df_stocked)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# Additional functionalities if needed\n",
    "\n",
    "# save the scores per team based on average with colors in images\n",
    "\n",
    "# calculate average and categorize performance with 6 levels\n",
    "metric_averages = df_stocked.mean()\n",
    "performance = pd.DataFrame(index=df_stocked.index, columns=df_stocked.columns)\n",
    "\n",
    "# Assign performance ratings for each team and metric using league average ± standard deviations\n",
    "for col in df_stocked.columns:\n",
    "    avg = metric_averages[col]\n",
    "    std = df_stocked[col].std()\n",
    "    for team in df_stocked.index:\n",
    "        val = df_stocked.loc[team, col]\n",
    "        if val >= avg + 2*std:\n",
    "            cat = \"+++\"  # very good performance (2+ std above avg)\n",
    "        elif val >= avg + std:\n",
    "            cat = \"++\"   # good performance (1-2 std above avg)\n",
    "        elif val >= avg:\n",
    "            cat = \"+\"    # Above average performance\n",
    "        elif val <= avg - 2*std:\n",
    "            cat = \"---\"  # Very poor performance (2+ std below avg)\n",
    "        elif val <= avg - std:\n",
    "            cat = \"--\"   # Poor performance (1-2 std below avg)\n",
    "        else:\n",
    "            cat = \"-\"    # Below average performance\n",
    "        performance.loc[team, col] = cat\n",
    "\n",
    "# combine value and label\n",
    "df_display = df_stocked.round(2).astype(str) + \" (\" + performance + \")\"\n",
    "df_display.loc[\"League Average\"] = [f\"{metric_averages[col]:.2f} (avg)\" for col in df_stocked.columns]\n",
    "\n",
    "# save Horizontal Table ----------\n",
    "plt.figure(figsize=(len(df_display.columns) * 2.2, len(df_display) * 0.35))\n",
    "sns.set(font_scale=0.72)\n",
    "table = plt.table(cellText=df_display.values,\n",
    "                  rowLabels=df_display.index,\n",
    "                  colLabels=df_display.columns,\n",
    "                  loc='center',\n",
    "                  cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(6.5)\n",
    "table.scale(1.05, 1.08)\n",
    "\n",
    "# add colors based on performance categories (6 levels)\n",
    "for i in range(len(df_display)):\n",
    "    for j in range(len(df_display.columns)):\n",
    "        cell_text = df_display.iloc[i, j]\n",
    "        if \"(+++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#006400')  # Very dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#2E8B57')  # Dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(+)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#90EE90')  # Light green\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(---)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#8B0000')  # Very dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(--)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#CD5C5C')  # Dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(-)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#FFB6C1')  # Light red\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(avg)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#D3D3D3')  # Light gray\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Team Tactical Metrics - Horizontal View', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.axis('off')\n",
    "#plt.savefig(\"team_tactical_metrics_performance_table_Ligue1_1516.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(\"\\nLegend:\")\n",
    "print(\"+++ (Very Dark Green): Exceptional - Above average + 2 standard deviations\")\n",
    "print(\"++ (Dark Green): Very Good - Above average + 1 standard deviation\")\n",
    "print(\"+ (Light Green): Good - Above average\")\n",
    "print(\"- (Light Red): Below average\")\n",
    "print(\"-- (Dark Red): Poor - Below average - 1 standard deviation\")\n",
    "print(\"--- (Very Dark Red): Very Poor - Below average - 2 standard deviations\")\n",
    "print(\"avg (Gray): League average\")\n",
    "\n",
    "# Display the categorized data \n",
    "print(\"\\n Performance Categories:\")\n",
    "print(performance)\n",
    "\n",
    "# Display average scores per metric\n",
    "print(\"\\n Average Scores per Metric:\")\n",
    "print(metric_averages.round(2))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# If you want to create 5 distinctive horizontal tables with the performance scores instead of one big image like above\n",
    "# Define metric groups\n",
    "#metric_groups = {\n",
    "#    \"Metrics 1-5\": df_display.iloc[:, 0:5],\n",
    "#    \"Metrics 6-10\": df_display.iloc[:, 5:10], \n",
    "#    \"Metrics 11-15\": df_display.iloc[:, 10:15],\n",
    "#    \"Metrics 16-20\": df_display.iloc[:, 15:20],\n",
    "#    \"Metrics 21-23\": df_display.iloc[:, 20:23]\n",
    "#}\n",
    "\n",
    "#def create_colored_table(df_subset, title, filename):\n",
    "#    \"\"\"Create a colored table for a subset of metrics\"\"\"\n",
    "#    plt.figure(figsize=(len(df_subset.columns) * 2.2, len(df_subset) * 0.35))\n",
    "#    sns.set(font_scale=0.72)\n",
    "    \n",
    "#    table = plt.table(cellText=df_subset.values,\n",
    "#                      rowLabels=df_subset.index,  # Team names on the side\n",
    "#                      colLabels=df_subset.columns,\n",
    "#                      loc='center',\n",
    "#                      cellLoc='center')\n",
    "    \n",
    "#    table.auto_set_font_size(False)\n",
    "#    table.set_fontsize(6.5)\n",
    "#    table.scale(1.05, 1.08)\n",
    "\n",
    "    # Add colors based on performance categories (5 levels)\n",
    "#    for i in range(len(df_subset)):\n",
    "#        for j in range(len(df_subset.columns)):\n",
    "#            cell_text = df_subset.iloc[i, j]\n",
    "#            if \"(+++)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#006400')  # Very dark green\n",
    "#                table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "#            elif \"(++)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#2E8B57')  # Dark green\n",
    "#                table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "#            elif \"(+)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#90EE90')  # Light green\n",
    "#                table[(i+1, j)].set_text_props(weight='bold')\n",
    "#            elif \"(---)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#8B0000')  # Very dark red\n",
    "#                table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "#            elif \"(--)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#CD5C5C')  # Dark red\n",
    "#                table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "#            elif \"(-)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#FFB6C1')  # Light red\n",
    "#                table[(i+1, j)].set_text_props(weight='bold')\n",
    "#            elif \"(avg)\" in str(cell_text):\n",
    "#                table[(i+1, j)].set_facecolor('#D3D3D3')  # Light gray\n",
    "#                table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "#    plt.title(f'Team Tactical Metrics - {title}', fontsize=14, fontweight='bold', pad=20)\n",
    "#    plt.axis('off')\n",
    "#    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "#    plt.show()\n",
    "#    print(f\"Created: {filename}\")\n",
    "\n",
    "# Create all 5 tables\n",
    "#for group_name, df_subset in metric_groups.items():\n",
    "#    filename = f\"tactical_metrics_{group_name.lower().replace(' ', '_').replace('-', '_')}.png\"\n",
    "#    create_colored_table(df_subset, group_name, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8636f-0984-45c9-a300-2424342c734b",
   "metadata": {},
   "source": [
    "## EFA-related indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e67d79-210f-4e8c-9f01-f6988807eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import plotly.express as px\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl import statsbomb as spadl_sb\n",
    "from socceraction import spadl\n",
    "from socceraction.vaep import features as feat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "#Load StatsBomb data locally\n",
    "sbl = StatsBombLoader(\n",
    "    getter=\"local\",  # from local files\n",
    "    root=\"C:/Users/helio/MachineLearning/Bachelor/statsbomb_data/open-data-master/data\"\n",
    ")\n",
    "\n",
    "# Get all games for a given competition and season\n",
    "# Competition ID = 2, Season ID = 27 (Premier League 2015/16)\n",
    "# Competition ID = 11, Season ID = 27 (La Liga 2015/16)\n",
    "# Competition ID = 9, Season ID = 27 (Bundesliga 2015/16)\n",
    "# Competition ID = 12, Season ID = 27 (Serie A 2015/16)\n",
    "# Competition ID = 7, Season ID = 27 (Ligue 1 2015/16)\n",
    "games = sbl.games(2, 27)\n",
    "\n",
    "# Load pre-trained VAEP model that some metrics need, especially VAEP metrics\n",
    "data = joblib.load(\"C:/Users/helio/MachineLearning/Bachelor/vaep_model_xgboost_5leagues_1516.pkl\")\n",
    "# The trained model\n",
    "model = data[\"model\"]          \n",
    "# Expected input features for model\n",
    "expected_columns = data[\"feature_columns\"] \n",
    "\n",
    "\n",
    "# Create a mapping of team ids to names for all matches of interest\n",
    "matches_of_interest = games[[\"game_id\", \"home_team_id\", \"away_team_id\"]].copy()\n",
    "team_id_name_map = {}\n",
    "for game_id in matches_of_interest[\"game_id\"]:\n",
    "    teams = sbl.teams(game_id)\n",
    "    for _, row in teams.iterrows():\n",
    "        team_id_name_map[row[\"team_id\"]] = row[\"team_name\"]\n",
    "\n",
    "# Add team names to match dataframe\n",
    "matches_of_interest[\"home_team_name\"] = matches_of_interest[\"home_team_id\"].map(team_id_name_map)\n",
    "matches_of_interest[\"away_team_name\"] = matches_of_interest[\"away_team_id\"].map(team_id_name_map)\n",
    "\n",
    "# Keep only rows with valid team names\n",
    "matches_of_interest = matches_of_interest.dropna(subset=[\"home_team_name\", \"away_team_name\"])\n",
    "\n",
    "\n",
    "# compute VAEP-based team metrics for a single match\n",
    "def evaluate_team_metrics(game_id, home_name, away_name, model):\n",
    "    # Load game and prepare base dataframe\n",
    "    match = games.loc[games[\"game_id\"] == game_id].iloc[0]\n",
    "    home_id, away_id = match[\"home_team_id\"], match[\"away_team_id\"]\n",
    "    events = sbl.events(game_id)\n",
    "    # convert to SPADL actions\n",
    "    actions = spadl.add_names(spadl_sb.convert_to_actions(events, home_id))\n",
    "    df = pd.DataFrame(index=[home_id, away_id])\n",
    "\n",
    "    # Predict VAEP\n",
    "    gamestates = feat.play_left_to_right(feat.gamestates(actions, nb_prev_actions=3), home_id)\n",
    "    X = pd.concat([f(gamestates) for f in [\n",
    "        feat.actiontype_onehot, feat.result_onehot, feat.bodypart_onehot,\n",
    "        feat.startlocation, feat.endlocation, feat.movement, feat.time\n",
    "    ]], axis=1)\n",
    "    for col in expected_columns:\n",
    "        if col not in X.columns:\n",
    "            X[col] = 0\n",
    "    X = X[expected_columns]\n",
    "    actions[\"vaep_pred\"] = model.predict(X)\n",
    "\n",
    "\n",
    "    # 1. Possession\n",
    "    actions[\"time_diff\"] = actions[\"time_seconds\"].diff().fillna(0)\n",
    "    total_time = actions.groupby(\"team_id\")[\"time_diff\"].sum()\n",
    "    df[\"Possession\"] = total_time / total_time.sum()\n",
    "\n",
    "    # Field thirds & zones\n",
    "    defensive_third = actions[\"start_x\"] <= 33.3\n",
    "    middle_third = (actions[\"start_x\"] > 33.3) & (actions[\"start_x\"] <= 66.6)\n",
    "    attacking_third = actions[\"start_x\"] > 66.6\n",
    "    central_area = actions[\"start_y\"].between(30, 50)\n",
    "    wide_area = (actions[\"start_y\"] < 20) | (actions[\"start_y\"] > 60)\n",
    "    team_time_possession = actions.groupby(\"team_id\")[\"time_diff\"].sum()\n",
    "\n",
    "    # 2–6: possession in different areas\n",
    "    df[\"PossDef3\"] = actions[defensive_third].groupby(\"team_id\")[\"time_diff\"].sum() / team_time_possession\n",
    "    df[\"PossMid3\"] = actions[middle_third].groupby(\"team_id\")[\"time_diff\"].sum() / team_time_possession\n",
    "    df[\"PossAtt3\"] = actions[attacking_third].groupby(\"team_id\")[\"time_diff\"].sum() / team_time_possession\n",
    "    df[\"PossCentral\"] = actions[central_area].groupby(\"team_id\")[\"time_diff\"].sum() / team_time_possession\n",
    "    df[\"PossWide\"] = actions[wide_area].groupby(\"team_id\")[\"time_diff\"].sum() / team_time_possession\n",
    "\n",
    "    # 7–10: Pass directions\n",
    "    passes = actions[actions[\"type_name\"] == \"pass\"]\n",
    "    dx = passes[\"end_x\"] - passes[\"start_x\"]\n",
    "    dy = passes[\"end_y\"] - passes[\"start_y\"]\n",
    "\n",
    "    def pass_direction(dx, dy):\n",
    "        if abs(dx) < abs(dy) and abs(dy) > 5:  # sideways\n",
    "            return \"side\"\n",
    "        elif dx > 5:\n",
    "            return \"forward\"\n",
    "        elif dx < -5:\n",
    "            return \"backward\"\n",
    "        else:\n",
    "            return \"side\"\n",
    "\n",
    "    passes[\"direction\"] = [pass_direction(x, y) for x, y in zip(dx, dy)]\n",
    "    direction_score = passes[\"direction\"].map({\"backward\": 1, \"side\": 2, \"forward\": 3})\n",
    "\n",
    "    df[\"PassDirectionScore\"] = passes.groupby(\"team_id\")[\"direction\"].apply(lambda s: s.map({\"backward\":1,\"side\":2,\"forward\":3}).mean())\n",
    "    df[\"ForwardPassPct\"] = (passes[\"direction\"] == \"forward\").groupby(passes[\"team_id\"]).mean()\n",
    "    df[\"SidePassPct\"] = (passes[\"direction\"] == \"side\").groupby(passes[\"team_id\"]).mean()\n",
    "    df[\"BackPassPct\"] = (passes[\"direction\"] == \"backward\").groupby(passes[\"team_id\"]).mean()\n",
    "\n",
    "    # 11–12: passes between thirds\n",
    "    from_def_to_mid = defensive_third & (passes[\"end_x\"] > 33.3) & (passes[\"end_x\"] <= 66.6)\n",
    "    from_def_to_att = defensive_third & (passes[\"end_x\"] > 66.6)\n",
    "    df[\"PassDefToMid\"] = from_def_to_mid.groupby(passes[\"team_id\"]).mean()\n",
    "    df[\"PassDefToAtt\"] = from_def_to_att.groupby(passes[\"team_id\"]).mean()\n",
    "\n",
    "    # 13: Crosses \n",
    "    crosses = passes[passes[\"type_name\"] == \"cross\"]\n",
    "    df[\"CrossPct\"] = crosses.groupby(\"team_id\").size() / passes.groupby(\"team_id\").size()\n",
    "\n",
    "    # 14: Shots \n",
    "    shots = actions[actions[\"type_name\"] == \"shot\"]\n",
    "    df[\"ShotPct\"] = shots.groupby(\"team_id\").size() / passes.groupby(\"team_id\").size()\n",
    "\n",
    "    # 15–19: Regains \n",
    "    regains = actions[actions[\"type_name\"].isin([\"interception\", \"tackle\", \"clearance\"])]\n",
    "    total_regains = regains.groupby(\"team_id\").size()\n",
    "\n",
    "    df[\"RegainDef3\"] = regains[defensive_third].groupby(\"team_id\").size() / total_regains\n",
    "    df[\"RegainMid3\"] = regains[middle_third].groupby(\"team_id\").size() / total_regains\n",
    "    df[\"RegainAtt3\"] = regains[attacking_third].groupby(\"team_id\").size() / total_regains\n",
    "    df[\"RegainCentral\"] = regains[central_area].groupby(\"team_id\").size() / total_regains\n",
    "    df[\"RegainWide\"] = regains[wide_area].groupby(\"team_id\").size() / total_regains\n",
    "\n",
    "    # fill missing values with 0\n",
    "    df = df.fillna(0)\n",
    "    # replace team ids with team names\n",
    "    df.index = df.index.map(lambda x: home_name if x == home_id else away_name)\n",
    "    return df\n",
    "\n",
    "# store cumulative metrics for all teams\n",
    "team_vaep_metrics = {}\n",
    "\n",
    "# loop through each match\n",
    "for _, row in tqdm(matches_of_interest.iterrows(), total=len(matches_of_interest)):\n",
    "    game_id = row[\"game_id\"]\n",
    "    home_name = row[\"home_team_name\"]\n",
    "    away_name = row[\"away_team_name\"]\n",
    "\n",
    "    # get metrics for this match\n",
    "    df = evaluate_team_metrics(game_id, home_name, away_name, model)\n",
    "\n",
    "    # add metrics to each team (sum over matches)\n",
    "    for team in df.index:\n",
    "        if team not in team_vaep_metrics:\n",
    "            team_vaep_metrics[team] = df.loc[team]  # first time just add\n",
    "        else:\n",
    "            team_vaep_metrics[team] += df.loc[team] # otherwise sum up\n",
    "\n",
    "# convert dictionary to DataFrame for readability\n",
    "df_stocked = pd.DataFrame(team_vaep_metrics).T.fillna(0)\n",
    "print(\"Data available in df_stocked\")\n",
    "print(df_stocked)\n",
    "\n",
    "\n",
    "def apply_pca_transformation(df_stocked, n_components=None, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to create latent tactical style components\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\" PCA-BASED TACTICAL STYLE TRANSFORMATION\")\n",
    "    \n",
    "    # prepare data\n",
    "    X = df_stocked.copy()\n",
    "    # make sure to have only one team and no duplicates\n",
    "    X = X.loc[~X.index.duplicated(keep='first')]\n",
    "\n",
    "    # CORRELATION ANALYSIS\n",
    "    print(\"\\n CORRELATION ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    # find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    print(f\"Highly correlated pairs (>0.7): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"   {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "    \n",
    "    # STANDARDIZATION\n",
    "    print(\"\\n DATA STANDARDIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\" Data standardized (mean=0, std=1)\")\n",
    "    \n",
    "    # PCA APPLICATION\n",
    "    print(\"\\n PCA APPLICATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # apply PCA with all components first to analyze variance\n",
    "    pca_full = PCA()\n",
    "    X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "    \n",
    "    # calculate cumulative variance\n",
    "    added_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    # determine the number of components\n",
    "    if n_components is None:\n",
    "        n_components = np.argmax(added_variance >= variance_threshold) + 1\n",
    "        print(f\"Components needed for {variance_threshold*100}% variance: {n_components}\")\n",
    "    \n",
    "    # apply PCA with the chosen number of components\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Final PCA shape: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Cumulative variance explained: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "    \n",
    "    # component interpretation\n",
    "    print(\"\\n TACTICAL STYLE COMPONENTS INTERPRETATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # create component interpretation\n",
    "    components_df = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.columns\n",
    "    )\n",
    "    \n",
    "    # interpret each component\n",
    "    tactical_styles = {}\n",
    "    for i in range(n_components):\n",
    "        component_name = f'Style_{i+1}'\n",
    "        component_loadings = components_df[component_name].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\n {component_name} (explains {pca.explained_variance_ratio_[i]:.1%} variance):\")\n",
    "        \n",
    "        # top positive loadings\n",
    "        pos_loadings = components_df[component_name].sort_values(ascending=False).head(3)\n",
    "        print(\"   Top positive loadings:\")\n",
    "        for feat, loading in pos_loadings.items():\n",
    "            print(f\"      +{loading:.3f} {feat}\")\n",
    "        \n",
    "        # top negative loadings\n",
    "        neg_loadings = components_df[component_name].sort_values(ascending=True).head(3)\n",
    "        print(\"   Top negative loadings:\")\n",
    "        for feat, loading in neg_loadings.items():\n",
    "            print(f\"      {loading:.3f} {feat}\")\n",
    "        \n",
    "        # suggest a tactical interpretation\n",
    "        top_features = component_loadings.head(3).index.tolist()\n",
    "        tactical_styles[component_name] = {\n",
    "            'variance_explained': pca.explained_variance_ratio_[i],\n",
    "            'top_features': top_features\n",
    "        }\n",
    "    \n",
    "    # Create a PCA dataFrame for visibility and better understandings\n",
    "    pca_df = pd.DataFrame(\n",
    "        X_pca, \n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'pca_df': pca_df,\n",
    "        'pca_model': pca,\n",
    "        'scaler': scaler,\n",
    "        'components_df': components_df,\n",
    "        'tactical_styles': tactical_styles,\n",
    "        'original_data': X,\n",
    "        'scaled_data': X_scaled,\n",
    "        'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "        'added_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "    }\n",
    "\n",
    "def cluster_pca_styles(pca_results, clustering_methods=None, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Apply clustering to PCA-transformed tactical styles\n",
    "    \"\"\"\n",
    "    # The 5 clustering algorithms\n",
    "    if clustering_methods is None:\n",
    "        clustering_methods = {\n",
    "            \"KMeans\": {\"n_clusters\": 9},\n",
    "            \"Agglomerative\": {\"n_clusters\": 9},\n",
    "            \"GMM\": {\"n_components\": 9},\n",
    "            \"Spectral\": {\"n_clusters\": 9},\n",
    "            \"Birch\": {\"n_clusters\": 6}\n",
    "        }\n",
    "    \n",
    "\n",
    "    # Extract the PCA-transformed feature matrix (scores) from results\n",
    "    # Get PCA scores as a NumPy array for clustering\n",
    "    pca_df = pca_results['pca_df']\n",
    "    X_pca = pca_df.values\n",
    "    \n",
    "    # standardize PCA components\n",
    "    scaler_pca = StandardScaler()\n",
    "    X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
    "\n",
    "\n",
    "    print(\"\\n OPTIMAL NUMBER OF CLUSTERS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Test different numbers of clusters\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    # metrics for different clustering algorithms\n",
    "    metrics = {\n",
    "        'KMeans': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Agglomerative': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'GMM': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Birch': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Spectral': {'silhouette': [], 'calinski': [], 'davies': []}\n",
    "    }\n",
    "\n",
    "    # Try different numbers of clusters for each algorithm and record quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    for n_clusters in cluster_range:\n",
    "        \n",
    "        # KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels_km = kmeans.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Agglomerative\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        labels_agg = agg.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # GMM\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        labels_gmm = gmm.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Birch \n",
    "        birch = Birch(n_clusters=n_clusters)\n",
    "        labels_birch = birch.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Spectral\n",
    "        try:\n",
    "            spectral = SpectralClustering(n_clusters=n_clusters, random_state=42, affinity='nearest_neighbors')\n",
    "            labels_spectral = spectral.fit_predict(X_pca_scaled)\n",
    "        except Exception as e:\n",
    "            print(f\"  Spectral clustering failed for {n_clusters} clusters: {e}\")\n",
    "            # créer des labels par défaut en cas d'échec\n",
    "            labels_spectral = np.zeros(len(X_pca_scaled), dtype=int)\n",
    "        \n",
    "        # calculate metrics \n",
    "        for name, labels in [('KMeans', labels_km), ('Agglomerative', labels_agg), \n",
    "                           ('GMM', labels_gmm), ('Birch', labels_birch), ('Spectral', labels_spectral)]:\n",
    "            if len(np.unique(labels)) > 1:  # Need at least 2 clusters for metrics (For 2D vizualisation)\n",
    "                try:\n",
    "                    metrics[name]['silhouette'].append(silhouette_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['calinski'].append(calinski_harabasz_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['davies'].append(davies_bouldin_score(X_pca_scaled, labels))\n",
    "                except Exception as e:\n",
    "                    print(f\"   Error calculating metrics for {name} with {n_clusters} clusters: {e}\")\n",
    "                    metrics[name]['silhouette'].append(0)\n",
    "                    metrics[name]['calinski'].append(0)\n",
    "                    metrics[name]['davies'].append(float('inf'))\n",
    "            else:\n",
    "                metrics[name]['silhouette'].append(0)\n",
    "                metrics[name]['calinski'].append(0)\n",
    "                metrics[name]['davies'].append(float('inf'))\n",
    "\n",
    "    # print optimal number of clusters\n",
    "    print(\"Optimal number of clusters by metric:\")\n",
    "    for algorithm in metrics.keys():\n",
    "        if metrics[algorithm]['silhouette']:\n",
    "            try:\n",
    "                best_sil = cluster_range[np.argmax(metrics[algorithm]['silhouette'])]\n",
    "                best_cal = cluster_range[np.argmax(metrics[algorithm]['calinski'])]\n",
    "                best_dav = cluster_range[np.argmin(metrics[algorithm]['davies'])]\n",
    "                print(f\"   {algorithm:>12}: Silhouette={best_sil}, Calinski={best_cal}, Davies-Bouldin={best_dav}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   {algorithm:>12}: Error calculating optimal clusters - {e}\")\n",
    "\n",
    "    # Print the full score table per algorithm\n",
    "    print(\"\\n Full clustering scores by number of clusters:\")\n",
    "    for algorithm in metrics:\n",
    "        print(f\"\\n {algorithm}\")\n",
    "        print(\"Clusters | Silhouette | Calinski-Harabasz | Davies-Bouldin\")\n",
    "        for i, n in enumerate(cluster_range):\n",
    "            if i < len(metrics[algorithm]['silhouette']):\n",
    "                sil = metrics[algorithm]['silhouette'][i]\n",
    "                cal = metrics[algorithm]['calinski'][i]\n",
    "                dav = metrics[algorithm]['davies'][i]\n",
    "                print(f\"{n:>8} | {sil:>10.3f} | {cal:>18.2f} | {dav:>15.3f}\")\n",
    "    \n",
    "    clustering_results = {}\n",
    "\n",
    "    # Fit each clustering algorithm with its chosen parameters on the PCA data\n",
    "    # compute quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    # store the results and print the composition of each cluster.\n",
    "    for method_name, params in clustering_methods.items():\n",
    "        print(f\"\\n {method_name} Clustering\")\n",
    "        \n",
    "        try:\n",
    "            if method_name == \"KMeans\":\n",
    "                model = KMeans(random_state=42, n_init=10, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Agglomerative\":\n",
    "                model = AgglomerativeClustering(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"GMM\":\n",
    "                model = GaussianMixture(random_state=42, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Spectral\":\n",
    "                model = SpectralClustering(random_state=42, affinity='nearest_neighbors', **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Birch\":  \n",
    "                model = Birch(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "            \n",
    "            # evaluate clustering quality\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                sil_score = silhouette_score(X_pca_scaled, labels)\n",
    "                cal_score = calinski_harabasz_score(X_pca_scaled, labels)\n",
    "                dav_score = davies_bouldin_score(X_pca_scaled, labels)\n",
    "                \n",
    "                print(f\"   Silhouette Score: {sil_score:.3f}\")\n",
    "                print(f\"   Calinski-Harabasz: {cal_score:.2f}\")\n",
    "                print(f\"   Davies-Bouldin: {dav_score:.3f}\")\n",
    "                \n",
    "                clustering_results[method_name] = {\n",
    "                    'labels': labels,\n",
    "                    'model': model,\n",
    "                    'silhouette': sil_score,\n",
    "                    'calinski': cal_score,\n",
    "                    'davies_bouldin': dav_score\n",
    "                }\n",
    "                \n",
    "                # Print cluster composition\n",
    "                print(f\"   Cluster composition:\")\n",
    "                for cluster_id in np.unique(labels):\n",
    "                    cluster_teams = pca_df.index[labels == cluster_id].tolist()\n",
    "                    print(f\"      Cluster {cluster_id}: {cluster_teams}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\" Error with {method_name}: {e}\")\n",
    "    \n",
    "    return clustering_results\n",
    "\n",
    "\n",
    "def visualize_pca_clusters(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Visualize clustering results on PCA space\n",
    "    \"\"\"\n",
    "    print(\"\\n CLUSTERING VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    #Extract PCA scores (teams and components) and variance ratios for labeling axes\n",
    "    pca_df = pca_results['pca_df']\n",
    "    explained_variance = pca_results['explained_variance_ratio']\n",
    "    \n",
    "    # create a visualization for each clustering method\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        sil_score = result['silhouette']\n",
    "        \n",
    "        # create plot dataframe\n",
    "        plot_df = pca_df.copy()\n",
    "        plot_df['Team'] = plot_df.index\n",
    "        plot_df['Cluster'] = labels.astype(str)\n",
    "        \n",
    "        # 2D visualization for first two components\n",
    "        if pca_df.shape[1] >= 2:\n",
    "            fig = px.scatter(\n",
    "                plot_df, x='Style_1', y='Style_2',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering on Tactical Styles',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})'},\n",
    "                width=1000, height=600\n",
    "            )\n",
    "            fig.update_traces(textposition='top center')\n",
    "            fig.show()\n",
    "        \n",
    "        # 3D visualization if we have at least 3 components\n",
    "        if pca_df.shape[1] >= 3:\n",
    "            fig = px.scatter_3d(\n",
    "                plot_df, x='Style_1', y='Style_2', z='Style_3',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering - 3D Tactical Space',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})',\n",
    "                       'Style_3': f'Style 3 ({explained_variance[2]:.1%})'},\n",
    "                width=1000, height=700\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "def compute_global_discriminant_features(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Compute average F-ratio (feature importance) across all clustering methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n GLOBAL MOST DISCRIMINANT FEATURES (FOR ALL CLUSTERINGS)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Prepare a dictionary to store F-ratios per feature for each clustering method\n",
    "    original_data = pca_results['original_data']\n",
    "    global_f_ratios = {feature: [] for feature in original_data.columns}\n",
    "\n",
    "    # Loop over results from each clustering algorithm\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        original_with_clusters = original_data.copy()\n",
    "        original_with_clusters['Cluster'] = labels\n",
    "        unique_clusters = np.unique(labels)\n",
    "\n",
    "        #Loop through every original metric (feature)\n",
    "        for feature in original_data.columns:\n",
    "            feature_values = original_with_clusters[feature].values\n",
    "            overall_mean = np.mean(feature_values)\n",
    "\n",
    "            between_ss = 0\n",
    "            within_ss = 0\n",
    "\n",
    "            # Loop through each cluster to accumulate between/within variance\n",
    "            for cluster_id in unique_clusters:\n",
    "                cluster_vals = original_with_clusters[original_with_clusters['Cluster'] == cluster_id][feature].values\n",
    "                cluster_mean = np.mean(cluster_vals)\n",
    "                between_ss += len(cluster_vals) * (cluster_mean - overall_mean) ** 2\n",
    "                within_ss += np.sum((cluster_vals - cluster_mean) ** 2)\n",
    "\n",
    "            # Compute the F-ratio: higher means the feature better separates clusters\n",
    "            f_ratio = between_ss / within_ss if within_ss > 0 else 0\n",
    "            # Save this F-ratio for the current feature and clustering method\n",
    "            global_f_ratios[feature].append(f_ratio)\n",
    "\n",
    "    # average F-ratios across algorithms\n",
    "    avg_f_ratios = [(feature, np.mean(f_vals)) for feature, f_vals in global_f_ratios.items()]\n",
    "    avg_f_ratios.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\" Averaged most discriminating features across clustering methods:\")\n",
    "    for i, (feature, avg_f) in enumerate(avg_f_ratios):\n",
    "        print(f\"   {i+1:2d}. {feature:<25} Avg F-ratio = {avg_f:.3f}\")\n",
    "\n",
    "    # main execution function\n",
    "def run_pca_tactical_analysis(df_stocked):\n",
    "    \"\"\"\n",
    "    Run a complete PCA-based tactical analysis\n",
    "    \"\"\"\n",
    "    # 1: Apply PCA transformation\n",
    "    pca_results = apply_pca_transformation(df_stocked, variance_threshold=0.85)\n",
    "    \n",
    "    # 2: Apply clustering to PCA components\n",
    "    clustering_results = cluster_pca_styles(pca_results, max_clusters=9)\n",
    "    \n",
    "    # 3: Visualize clustering results\n",
    "    visualize_pca_clusters(pca_results, clustering_results)\n",
    "\n",
    "    # 4: Compute global discriminant features across all clusterings\n",
    "    compute_global_discriminant_features(pca_results, clustering_results)\n",
    "\n",
    "    #Return results for further analysis\n",
    "    return {\n",
    "        'pca_results': pca_results,\n",
    "        'clustering_results': clustering_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Run main function\n",
    "results = run_pca_tactical_analysis(df_stocked)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# Additional functionalities if needed\n",
    "\n",
    "# save the scores per team based on average with colors in images\n",
    "\n",
    "# calculate average and categorize performance with 6 levels\n",
    "metric_averages = df_stocked.mean()\n",
    "performance = pd.DataFrame(index=df_stocked.index, columns=df_stocked.columns)\n",
    "\n",
    "# Assign performance ratings for each team and metric using league average ± standard deviations\n",
    "for col in df_stocked.columns:\n",
    "    avg = metric_averages[col]\n",
    "    std = df_stocked[col].std()\n",
    "    for team in df_stocked.index:\n",
    "        val = df_stocked.loc[team, col]\n",
    "        if val >= avg + 2*std:\n",
    "            cat = \"+++\"  # very good performance (2+ std above avg)\n",
    "        elif val >= avg + std:\n",
    "            cat = \"++\"   # good performance (1-2 std above avg)\n",
    "        elif val >= avg:\n",
    "            cat = \"+\"    # Above average performance\n",
    "        elif val <= avg - 2*std:\n",
    "            cat = \"---\"  # Very poor performance (2+ std below avg)\n",
    "        elif val <= avg - std:\n",
    "            cat = \"--\"   # Poor performance (1-2 std below avg)\n",
    "        else:\n",
    "            cat = \"-\"    # Below average performance\n",
    "        performance.loc[team, col] = cat\n",
    "\n",
    "# combine value and label\n",
    "df_display = df_stocked.round(2).astype(str) + \" (\" + performance + \")\"\n",
    "df_display.loc[\"League Average\"] = [f\"{metric_averages[col]:.2f} (avg)\" for col in df_stocked.columns]\n",
    "\n",
    "# save Horizontal Table ----------\n",
    "plt.figure(figsize=(len(df_display.columns) * 2.2, len(df_display) * 0.35))\n",
    "sns.set(font_scale=0.72)\n",
    "table = plt.table(cellText=df_display.values,\n",
    "                  rowLabels=df_display.index,\n",
    "                  colLabels=df_display.columns,\n",
    "                  loc='center',\n",
    "                  cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(6.5)\n",
    "table.scale(1.05, 1.08)\n",
    "\n",
    "# add colors based on performance categories (6 levels)\n",
    "for i in range(len(df_display)):\n",
    "    for j in range(len(df_display.columns)):\n",
    "        cell_text = df_display.iloc[i, j]\n",
    "        if \"(+++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#006400')  # Very dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#2E8B57')  # Dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(+)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#90EE90')  # Light green\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(---)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#8B0000')  # Very dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(--)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#CD5C5C')  # Dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(-)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#FFB6C1')  # Light red\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(avg)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#D3D3D3')  # Light gray\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Team Tactical Metrics - Horizontal View', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"team_tactical_metrics_performance_table_PremierLeague_1516_EFA.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(\"\\nLegend:\")\n",
    "print(\"+++ (Very Dark Green): Exceptional - Above average + 2 standard deviations\")\n",
    "print(\"++ (Dark Green): Very Good - Above average + 1 standard deviation\")\n",
    "print(\"+ (Light Green): Good - Above average\")\n",
    "print(\"- (Light Red): Below average\")\n",
    "print(\"-- (Dark Red): Poor - Below average - 1 standard deviation\")\n",
    "print(\"--- (Very Dark Red): Very Poor - Below average - 2 standard deviations\")\n",
    "print(\"avg (Gray): League average\")\n",
    "\n",
    "# Display the categorized data \n",
    "print(\"\\n Performance Categories:\")\n",
    "print(performance)\n",
    "\n",
    "# Display average scores per metric\n",
    "print(\"\\n Average Scores per Metric:\")\n",
    "print(metric_averages.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ad372-c8b0-4efc-93df-c302bd94dceb",
   "metadata": {},
   "source": [
    "## VAEP metrics only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb99b4c-faa1-418e-8246-e3458227dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import plotly.express as px\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl import statsbomb as spadl_sb\n",
    "from socceraction import spadl\n",
    "from socceraction.vaep import features as feat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "#Load StatsBomb data locally\n",
    "sbl = StatsBombLoader(\n",
    "    getter=\"local\",  # from local files\n",
    "    root=\"C:/Users/helio/MachineLearning/Bachelor/statsbomb_data/open-data-master/data\"\n",
    ")\n",
    "\n",
    "# Get all games for a given competition and season\n",
    "# Competition ID = 2, Season ID = 27 (Premier League 2015/16)\n",
    "# Competition ID = 11, Season ID = 27 (La Liga 2015/16)\n",
    "# Competition ID = 9, Season ID = 27 (Bundesliga 2015/16)\n",
    "# Competition ID = 12, Season ID = 27 (Serie A 2015/16)\n",
    "# Competition ID = 7, Season ID = 27 (Ligue 1 2015/16)\n",
    "games = sbl.games(2, 27)\n",
    "\n",
    "# Load pre-trained VAEP model that some metrics need, especially VAEP metrics\n",
    "data = joblib.load(\"C:/Users/helio/MachineLearning/Bachelor/vaep_model_xgboost_5leagues_1516.pkl\")\n",
    "# The trained model\n",
    "model = data[\"model\"]          \n",
    "# Expected input features for model\n",
    "expected_columns = data[\"feature_columns\"] \n",
    "\n",
    "\n",
    "# Create a mapping of team ids to names for all matches of interest\n",
    "matches_of_interest = games[[\"game_id\", \"home_team_id\", \"away_team_id\"]].copy()\n",
    "team_id_name_map = {}\n",
    "for game_id in matches_of_interest[\"game_id\"]:\n",
    "    teams = sbl.teams(game_id)\n",
    "    for _, row in teams.iterrows():\n",
    "        team_id_name_map[row[\"team_id\"]] = row[\"team_name\"]\n",
    "\n",
    "# Add team names to match dataframe\n",
    "matches_of_interest[\"home_team_name\"] = matches_of_interest[\"home_team_id\"].map(team_id_name_map)\n",
    "matches_of_interest[\"away_team_name\"] = matches_of_interest[\"away_team_id\"].map(team_id_name_map)\n",
    "\n",
    "# Keep only rows with valid team names\n",
    "matches_of_interest = matches_of_interest.dropna(subset=[\"home_team_name\", \"away_team_name\"])\n",
    "\n",
    "\n",
    "# compute VAEP-based team metrics for a single match\n",
    "def evaluate_team_metrics(game_id, home_name, away_name, model):\n",
    "    \"\"\"\n",
    "    Given a match ID and team names, computes various metrics\n",
    "    \"\"\"\n",
    "    # Get match info\n",
    "    match = games.loc[games[\"game_id\"] == game_id].iloc[0]\n",
    "    home_id, away_id = match[\"home_team_id\"], match[\"away_team_id\"]\n",
    "    # Load raw events for the game\n",
    "    events = sbl.events(game_id)\n",
    "    # Convert StatsBomb events to SPADL format and add action names\n",
    "    actions = spadl.add_names(spadl_sb.convert_to_actions(events, home_id))\n",
    "    # Prepare output DataFrame indexed by team IDs\n",
    "    df = pd.DataFrame(index=[home_id, away_id])\n",
    "\n",
    "    # predict VAEP values for each action\n",
    "    gamestates = feat.play_left_to_right(feat.gamestates(actions, nb_prev_actions=3), home_id)\n",
    "\n",
    "    # Build feature matrix using multiple encoders\n",
    "    X = pd.concat([f(gamestates) for f in [\n",
    "        feat.actiontype_onehot, feat.result_onehot, feat.bodypart_onehot, feat.startlocation,\n",
    "        feat.endlocation, feat.movement, feat.time\n",
    "    ]], axis=1)\n",
    "\n",
    "    # ensure all expected columns exist , fill missing ones with 0\n",
    "    for col in expected_columns:\n",
    "        if col not in X.columns:\n",
    "            X[col] = 0\n",
    "    X = X[expected_columns]\n",
    "    # Predict VAEP for each action\n",
    "    actions[\"vaep_pred\"] = model.predict(X)\n",
    "\n",
    "\n",
    "    # VAEP metrics\n",
    "    df[\"VAEP_Passes\"] = actions[actions[\"type_name\"] == \"pass\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Crosses\"] = actions[actions[\"type_name\"].isin([\"cross\", \"freekick_crossed\", \"corner_crossed\"])].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Dribbles\"] = actions[actions[\"type_name\"] == \"dribble\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Shot\"] = actions[actions[\"type_name\"] == \"shot\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Clearance\"] = actions[actions[\"type_name\"] == \"clearance\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Interception\"] = actions[actions[\"type_name\"] == \"interception\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Foul\"] = actions[actions[\"type_name\"] == \"foul\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Tackle\"] = actions[actions[\"type_name\"] == \"tackle\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_BadTouch\"] = actions[actions[\"type_name\"] == \"bad_touch\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_KeeperSave\"] = actions[actions[\"type_name\"] == \"keeper_save\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "\n",
    "    \n",
    "    # fill missing values with 0\n",
    "    df = df.fillna(0)\n",
    "    # replace team ids with team names\n",
    "    df.index = df.index.map(lambda x: home_name if x == home_id else away_name)\n",
    "    return df\n",
    "\n",
    "# store cumulative metrics for all teams\n",
    "team_vaep_metrics = {}\n",
    "\n",
    "# loop through each match\n",
    "for _, row in tqdm(matches_of_interest.iterrows(), total=len(matches_of_interest)):\n",
    "    game_id = row[\"game_id\"]\n",
    "    home_name = row[\"home_team_name\"]\n",
    "    away_name = row[\"away_team_name\"]\n",
    "\n",
    "    # get metrics for this match\n",
    "    df = evaluate_team_metrics(game_id, home_name, away_name, model)\n",
    "\n",
    "    # add metrics to each team (sum over matches)\n",
    "    for team in df.index:\n",
    "        if team not in team_vaep_metrics:\n",
    "            team_vaep_metrics[team] = df.loc[team]  # first time just add\n",
    "        else:\n",
    "            team_vaep_metrics[team] += df.loc[team] # otherwise sum up\n",
    "\n",
    "# convert dictionary to DataFrame for readability\n",
    "df_stocked = pd.DataFrame(team_vaep_metrics).T.fillna(0)\n",
    "print(\"Data available in df_stocked\")\n",
    "print(df_stocked)\n",
    "\n",
    "\n",
    "def apply_pca_transformation(df_stocked, n_components=None, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to create latent tactical style components\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\" PCA-BASED TACTICAL STYLE TRANSFORMATION\")\n",
    "    \n",
    "    # prepare data\n",
    "    X = df_stocked.copy()\n",
    "    # make sure to have only one team and no duplicates\n",
    "    X = X.loc[~X.index.duplicated(keep='first')]\n",
    "\n",
    "    # CORRELATION ANALYSIS\n",
    "    print(\"\\n CORRELATION ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    # find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    print(f\"Highly correlated pairs (>0.7): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"   {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "    \n",
    "    # STANDARDIZATION\n",
    "    print(\"\\n DATA STANDARDIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\" Data standardized (mean=0, std=1)\")\n",
    "    \n",
    "    # PCA APPLICATION\n",
    "    print(\"\\n PCA APPLICATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # apply PCA with all components first to analyze variance\n",
    "    pca_full = PCA()\n",
    "    X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "    \n",
    "    # calculate cumulative variance\n",
    "    added_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    # determine the number of components\n",
    "    if n_components is None:\n",
    "        n_components = np.argmax(added_variance >= variance_threshold) + 1\n",
    "        print(f\"Components needed for {variance_threshold*100}% variance: {n_components}\")\n",
    "    \n",
    "    # apply PCA with the chosen number of components\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Final PCA shape: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Cumulative variance explained: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "    \n",
    "    # component interpretation\n",
    "    print(\"\\n TACTICAL STYLE COMPONENTS INTERPRETATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # create component interpretation\n",
    "    components_df = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.columns\n",
    "    )\n",
    "    \n",
    "    # interpret each component\n",
    "    tactical_styles = {}\n",
    "    for i in range(n_components):\n",
    "        component_name = f'Style_{i+1}'\n",
    "        component_loadings = components_df[component_name].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\n {component_name} (explains {pca.explained_variance_ratio_[i]:.1%} variance):\")\n",
    "        \n",
    "        # top positive loadings\n",
    "        pos_loadings = components_df[component_name].sort_values(ascending=False).head(3)\n",
    "        print(\"   Top positive loadings:\")\n",
    "        for feat, loading in pos_loadings.items():\n",
    "            print(f\"      +{loading:.3f} {feat}\")\n",
    "        \n",
    "        # top negative loadings\n",
    "        neg_loadings = components_df[component_name].sort_values(ascending=True).head(3)\n",
    "        print(\"   Top negative loadings:\")\n",
    "        for feat, loading in neg_loadings.items():\n",
    "            print(f\"      {loading:.3f} {feat}\")\n",
    "        \n",
    "        # suggest a tactical interpretation\n",
    "        top_features = component_loadings.head(3).index.tolist()\n",
    "        tactical_styles[component_name] = {\n",
    "            'variance_explained': pca.explained_variance_ratio_[i],\n",
    "            'top_features': top_features\n",
    "        }\n",
    "    \n",
    "    # Create a PCA dataFrame for visibility and better understandings\n",
    "    pca_df = pd.DataFrame(\n",
    "        X_pca, \n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'pca_df': pca_df,\n",
    "        'pca_model': pca,\n",
    "        'scaler': scaler,\n",
    "        'components_df': components_df,\n",
    "        'tactical_styles': tactical_styles,\n",
    "        'original_data': X,\n",
    "        'scaled_data': X_scaled,\n",
    "        'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "        'added_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "    }\n",
    "\n",
    "def cluster_pca_styles(pca_results, clustering_methods=None, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Apply clustering to PCA-transformed tactical styles\n",
    "    \"\"\"\n",
    "    # The 5 clustering algorithms\n",
    "    if clustering_methods is None:\n",
    "        clustering_methods = {\n",
    "            \"KMeans\": {\"n_clusters\": 9},\n",
    "            \"Agglomerative\": {\"n_clusters\": 9},\n",
    "            \"GMM\": {\"n_components\": 9},\n",
    "            \"Spectral\": {\"n_clusters\": 9},\n",
    "            \"Birch\": {\"n_clusters\": 6}\n",
    "        }\n",
    "    \n",
    "\n",
    "    # Extract the PCA-transformed feature matrix (scores) from results\n",
    "    # Get PCA scores as a NumPy array for clustering\n",
    "    pca_df = pca_results['pca_df']\n",
    "    X_pca = pca_df.values\n",
    "    \n",
    "    # standardize PCA components\n",
    "    scaler_pca = StandardScaler()\n",
    "    X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
    "\n",
    "\n",
    "    print(\"\\n OPTIMAL NUMBER OF CLUSTERS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Test different numbers of clusters\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    # metrics for different clustering algorithms\n",
    "    metrics = {\n",
    "        'KMeans': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Agglomerative': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'GMM': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Birch': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Spectral': {'silhouette': [], 'calinski': [], 'davies': []}\n",
    "    }\n",
    "\n",
    "    # Try different numbers of clusters for each algorithm and record quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    for n_clusters in cluster_range:\n",
    "        \n",
    "        # KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels_km = kmeans.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Agglomerative\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        labels_agg = agg.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # GMM\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        labels_gmm = gmm.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Birch \n",
    "        birch = Birch(n_clusters=n_clusters)\n",
    "        labels_birch = birch.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Spectral\n",
    "        try:\n",
    "            spectral = SpectralClustering(n_clusters=n_clusters, random_state=42, affinity='nearest_neighbors')\n",
    "            labels_spectral = spectral.fit_predict(X_pca_scaled)\n",
    "        except Exception as e:\n",
    "            print(f\"  Spectral clustering failed for {n_clusters} clusters: {e}\")\n",
    "            # créer des labels par défaut en cas d'échec\n",
    "            labels_spectral = np.zeros(len(X_pca_scaled), dtype=int)\n",
    "        \n",
    "        # calculate metrics \n",
    "        for name, labels in [('KMeans', labels_km), ('Agglomerative', labels_agg), \n",
    "                           ('GMM', labels_gmm), ('Birch', labels_birch), ('Spectral', labels_spectral)]:\n",
    "            if len(np.unique(labels)) > 1:  # Need at least 2 clusters for metrics (For 2D vizualisation)\n",
    "                try:\n",
    "                    metrics[name]['silhouette'].append(silhouette_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['calinski'].append(calinski_harabasz_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['davies'].append(davies_bouldin_score(X_pca_scaled, labels))\n",
    "                except Exception as e:\n",
    "                    print(f\"   Error calculating metrics for {name} with {n_clusters} clusters: {e}\")\n",
    "                    metrics[name]['silhouette'].append(0)\n",
    "                    metrics[name]['calinski'].append(0)\n",
    "                    metrics[name]['davies'].append(float('inf'))\n",
    "            else:\n",
    "                metrics[name]['silhouette'].append(0)\n",
    "                metrics[name]['calinski'].append(0)\n",
    "                metrics[name]['davies'].append(float('inf'))\n",
    "\n",
    "    # print optimal number of clusters\n",
    "    print(\"Optimal number of clusters by metric:\")\n",
    "    for algorithm in metrics.keys():\n",
    "        if metrics[algorithm]['silhouette']:\n",
    "            try:\n",
    "                best_sil = cluster_range[np.argmax(metrics[algorithm]['silhouette'])]\n",
    "                best_cal = cluster_range[np.argmax(metrics[algorithm]['calinski'])]\n",
    "                best_dav = cluster_range[np.argmin(metrics[algorithm]['davies'])]\n",
    "                print(f\"   {algorithm:>12}: Silhouette={best_sil}, Calinski={best_cal}, Davies-Bouldin={best_dav}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   {algorithm:>12}: Error calculating optimal clusters - {e}\")\n",
    "\n",
    "    # Print the full score table per algorithm\n",
    "    print(\"\\n Full clustering scores by number of clusters:\")\n",
    "    for algorithm in metrics:\n",
    "        print(f\"\\n {algorithm}\")\n",
    "        print(\"Clusters | Silhouette | Calinski-Harabasz | Davies-Bouldin\")\n",
    "        for i, n in enumerate(cluster_range):\n",
    "            if i < len(metrics[algorithm]['silhouette']):\n",
    "                sil = metrics[algorithm]['silhouette'][i]\n",
    "                cal = metrics[algorithm]['calinski'][i]\n",
    "                dav = metrics[algorithm]['davies'][i]\n",
    "                print(f\"{n:>8} | {sil:>10.3f} | {cal:>18.2f} | {dav:>15.3f}\")\n",
    "    \n",
    "    clustering_results = {}\n",
    "\n",
    "    # Fit each clustering algorithm with its chosen parameters on the PCA data\n",
    "    # compute quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    # store the results and print the composition of each cluster.\n",
    "    for method_name, params in clustering_methods.items():\n",
    "        print(f\"\\n {method_name} Clustering\")\n",
    "        \n",
    "        try:\n",
    "            if method_name == \"KMeans\":\n",
    "                model = KMeans(random_state=42, n_init=10, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Agglomerative\":\n",
    "                model = AgglomerativeClustering(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"GMM\":\n",
    "                model = GaussianMixture(random_state=42, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Spectral\":\n",
    "                model = SpectralClustering(random_state=42, affinity='nearest_neighbors', **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Birch\":  \n",
    "                model = Birch(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "            \n",
    "            # evaluate clustering quality\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                sil_score = silhouette_score(X_pca_scaled, labels)\n",
    "                cal_score = calinski_harabasz_score(X_pca_scaled, labels)\n",
    "                dav_score = davies_bouldin_score(X_pca_scaled, labels)\n",
    "                \n",
    "                print(f\"   Silhouette Score: {sil_score:.3f}\")\n",
    "                print(f\"   Calinski-Harabasz: {cal_score:.2f}\")\n",
    "                print(f\"   Davies-Bouldin: {dav_score:.3f}\")\n",
    "                \n",
    "                clustering_results[method_name] = {\n",
    "                    'labels': labels,\n",
    "                    'model': model,\n",
    "                    'silhouette': sil_score,\n",
    "                    'calinski': cal_score,\n",
    "                    'davies_bouldin': dav_score\n",
    "                }\n",
    "                \n",
    "                # Print cluster composition\n",
    "                print(f\"   Cluster composition:\")\n",
    "                for cluster_id in np.unique(labels):\n",
    "                    cluster_teams = pca_df.index[labels == cluster_id].tolist()\n",
    "                    print(f\"      Cluster {cluster_id}: {cluster_teams}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\" Error with {method_name}: {e}\")\n",
    "    \n",
    "    return clustering_results\n",
    "\n",
    "\n",
    "def visualize_pca_clusters(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Visualize clustering results on PCA space\n",
    "    \"\"\"\n",
    "    print(\"\\n CLUSTERING VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    #Extract PCA scores (teams and components) and variance ratios for labeling axes\n",
    "    pca_df = pca_results['pca_df']\n",
    "    explained_variance = pca_results['explained_variance_ratio']\n",
    "    \n",
    "    # create a visualization for each clustering method\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        sil_score = result['silhouette']\n",
    "        \n",
    "        # create plot dataframe\n",
    "        plot_df = pca_df.copy()\n",
    "        plot_df['Team'] = plot_df.index\n",
    "        plot_df['Cluster'] = labels.astype(str)\n",
    "        \n",
    "        # 2D visualization for first two components\n",
    "        if pca_df.shape[1] >= 2:\n",
    "            fig = px.scatter(\n",
    "                plot_df, x='Style_1', y='Style_2',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering on Tactical Styles',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})'},\n",
    "                width=1000, height=600\n",
    "            )\n",
    "            fig.update_traces(textposition='top center')\n",
    "            fig.show()\n",
    "        \n",
    "        # 3D visualization if we have at least 3 components\n",
    "        if pca_df.shape[1] >= 3:\n",
    "            fig = px.scatter_3d(\n",
    "                plot_df, x='Style_1', y='Style_2', z='Style_3',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering - 3D Tactical Space',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})',\n",
    "                       'Style_3': f'Style 3 ({explained_variance[2]:.1%})'},\n",
    "                width=1000, height=700\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "def compute_global_discriminant_features(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Compute average F-ratio (feature importance) across all clustering methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n GLOBAL MOST DISCRIMINANT FEATURES (FOR ALL CLUSTERINGS)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Prepare a dictionary to store F-ratios per feature for each clustering method\n",
    "    original_data = pca_results['original_data']\n",
    "    global_f_ratios = {feature: [] for feature in original_data.columns}\n",
    "\n",
    "    # Loop over results from each clustering algorithm\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        original_with_clusters = original_data.copy()\n",
    "        original_with_clusters['Cluster'] = labels\n",
    "        unique_clusters = np.unique(labels)\n",
    "\n",
    "        #Loop through every original metric (feature)\n",
    "        for feature in original_data.columns:\n",
    "            feature_values = original_with_clusters[feature].values\n",
    "            overall_mean = np.mean(feature_values)\n",
    "\n",
    "            between_ss = 0\n",
    "            within_ss = 0\n",
    "\n",
    "            # Loop through each cluster to accumulate between/within variance\n",
    "            for cluster_id in unique_clusters:\n",
    "                cluster_vals = original_with_clusters[original_with_clusters['Cluster'] == cluster_id][feature].values\n",
    "                cluster_mean = np.mean(cluster_vals)\n",
    "                between_ss += len(cluster_vals) * (cluster_mean - overall_mean) ** 2\n",
    "                within_ss += np.sum((cluster_vals - cluster_mean) ** 2)\n",
    "\n",
    "            # Compute the F-ratio: higher means the feature better separates clusters\n",
    "            f_ratio = between_ss / within_ss if within_ss > 0 else 0\n",
    "            # Save this F-ratio for the current feature and clustering method\n",
    "            global_f_ratios[feature].append(f_ratio)\n",
    "\n",
    "    # average F-ratios across algorithms\n",
    "    avg_f_ratios = [(feature, np.mean(f_vals)) for feature, f_vals in global_f_ratios.items()]\n",
    "    avg_f_ratios.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\" Averaged most discriminating features across clustering methods:\")\n",
    "    for i, (feature, avg_f) in enumerate(avg_f_ratios):\n",
    "        print(f\"   {i+1:2d}. {feature:<25} Avg F-ratio = {avg_f:.3f}\")\n",
    "\n",
    "    # main execution function\n",
    "def run_pca_tactical_analysis(df_stocked):\n",
    "    \"\"\"\n",
    "    Run a complete PCA-based tactical analysis\n",
    "    \"\"\"\n",
    "    # 1: Apply PCA transformation\n",
    "    pca_results = apply_pca_transformation(df_stocked, variance_threshold=0.85)\n",
    "    \n",
    "    # 2: Apply clustering to PCA components\n",
    "    clustering_results = cluster_pca_styles(pca_results, max_clusters=9)\n",
    "    \n",
    "    # 3: Visualize clustering results\n",
    "    visualize_pca_clusters(pca_results, clustering_results)\n",
    "\n",
    "    # 4: Compute global discriminant features across all clusterings\n",
    "    compute_global_discriminant_features(pca_results, clustering_results)\n",
    "\n",
    "    #Return results for further analysis\n",
    "    return {\n",
    "        'pca_results': pca_results,\n",
    "        'clustering_results': clustering_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Run main function\n",
    "results = run_pca_tactical_analysis(df_stocked)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# Additional functionalities if needed\n",
    "\n",
    "# save the scores per team based on average with colors in images\n",
    "\n",
    "# calculate average and categorize performance with 6 levels\n",
    "metric_averages = df_stocked.mean()\n",
    "performance = pd.DataFrame(index=df_stocked.index, columns=df_stocked.columns)\n",
    "\n",
    "# Assign performance ratings for each team and metric using league average ± standard deviations\n",
    "for col in df_stocked.columns:\n",
    "    avg = metric_averages[col]\n",
    "    std = df_stocked[col].std()\n",
    "    for team in df_stocked.index:\n",
    "        val = df_stocked.loc[team, col]\n",
    "        if val >= avg + 2*std:\n",
    "            cat = \"+++\"  # very good performance (2+ std above avg)\n",
    "        elif val >= avg + std:\n",
    "            cat = \"++\"   # good performance (1-2 std above avg)\n",
    "        elif val >= avg:\n",
    "            cat = \"+\"    # Above average performance\n",
    "        elif val <= avg - 2*std:\n",
    "            cat = \"---\"  # Very poor performance (2+ std below avg)\n",
    "        elif val <= avg - std:\n",
    "            cat = \"--\"   # Poor performance (1-2 std below avg)\n",
    "        else:\n",
    "            cat = \"-\"    # Below average performance\n",
    "        performance.loc[team, col] = cat\n",
    "\n",
    "# combine value and label\n",
    "df_display = df_stocked.round(2).astype(str) + \" (\" + performance + \")\"\n",
    "df_display.loc[\"League Average\"] = [f\"{metric_averages[col]:.2f} (avg)\" for col in df_stocked.columns]\n",
    "\n",
    "# save Horizontal Table ----------\n",
    "plt.figure(figsize=(len(df_display.columns) * 2.2, len(df_display) * 0.35))\n",
    "sns.set(font_scale=0.72)\n",
    "table = plt.table(cellText=df_display.values,\n",
    "                  rowLabels=df_display.index,\n",
    "                  colLabels=df_display.columns,\n",
    "                  loc='center',\n",
    "                  cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(6.5)\n",
    "table.scale(1.05, 1.08)\n",
    "\n",
    "# add colors based on performance categories (6 levels)\n",
    "for i in range(len(df_display)):\n",
    "    for j in range(len(df_display.columns)):\n",
    "        cell_text = df_display.iloc[i, j]\n",
    "        if \"(+++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#006400')  # Very dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#2E8B57')  # Dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(+)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#90EE90')  # Light green\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(---)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#8B0000')  # Very dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(--)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#CD5C5C')  # Dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(-)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#FFB6C1')  # Light red\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(avg)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#D3D3D3')  # Light gray\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Team Tactical Metrics - Horizontal View', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"team_tactical_metrics_performance_table_PremierLeague_1516_VAPEONLY.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(\"\\nLegend:\")\n",
    "print(\"+++ (Very Dark Green): Exceptional - Above average + 2 standard deviations\")\n",
    "print(\"++ (Dark Green): Very Good - Above average + 1 standard deviation\")\n",
    "print(\"+ (Light Green): Good - Above average\")\n",
    "print(\"- (Light Red): Below average\")\n",
    "print(\"-- (Dark Red): Poor - Below average - 1 standard deviation\")\n",
    "print(\"--- (Very Dark Red): Very Poor - Below average - 2 standard deviations\")\n",
    "print(\"avg (Gray): League average\")\n",
    "\n",
    "# Display the categorized data \n",
    "print(\"\\n Performance Categories:\")\n",
    "print(performance)\n",
    "\n",
    "# Display average scores per metric\n",
    "print(\"\\n Average Scores per Metric:\")\n",
    "print(metric_averages.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3dc53-8cb4-4bf6-854e-ee1e6fe30fc8",
   "metadata": {},
   "source": [
    "## VAEP + other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be41b6-3623-4bc7-b866-a26da0305320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import plotly.express as px\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl import statsbomb as spadl_sb\n",
    "from socceraction import spadl\n",
    "from socceraction.vaep import features as feat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "\n",
    "#Load StatsBomb data locally\n",
    "sbl = StatsBombLoader(\n",
    "    getter=\"local\",  # from local files\n",
    "    root=\"C:/Users/helio/MachineLearning/Bachelor/statsbomb_data/open-data-master/data\"\n",
    ")\n",
    "\n",
    "# Get all games for a given competition and season\n",
    "# Competition ID = 2, Season ID = 27 (Premier League 2015/16)\n",
    "# Competition ID = 11, Season ID = 27 (La Liga 2015/16)\n",
    "# Competition ID = 9, Season ID = 27 (Bundesliga 2015/16)\n",
    "# Competition ID = 12, Season ID = 27 (Serie A 2015/16)\n",
    "# Competition ID = 7, Season ID = 27 (Ligue 1 2015/16)\n",
    "games = sbl.games(2, 27)\n",
    "\n",
    "# Load pre-trained VAEP model that some metrics need, especially VAEP metrics\n",
    "data = joblib.load(\"C:/Users/helio/MachineLearning/Bachelor/vaep_model_xgboost_5leagues_1516.pkl\")\n",
    "# The trained model\n",
    "model = data[\"model\"]          \n",
    "# Expected input features for model\n",
    "expected_columns = data[\"feature_columns\"] \n",
    "\n",
    "\n",
    "# Create a mapping of team ids to names for all matches of interest\n",
    "matches_of_interest = games[[\"game_id\", \"home_team_id\", \"away_team_id\"]].copy()\n",
    "team_id_name_map = {}\n",
    "for game_id in matches_of_interest[\"game_id\"]:\n",
    "    teams = sbl.teams(game_id)\n",
    "    for _, row in teams.iterrows():\n",
    "        team_id_name_map[row[\"team_id\"]] = row[\"team_name\"]\n",
    "\n",
    "# Add team names to match dataframe\n",
    "matches_of_interest[\"home_team_name\"] = matches_of_interest[\"home_team_id\"].map(team_id_name_map)\n",
    "matches_of_interest[\"away_team_name\"] = matches_of_interest[\"away_team_id\"].map(team_id_name_map)\n",
    "\n",
    "# Keep only rows with valid team names\n",
    "matches_of_interest = matches_of_interest.dropna(subset=[\"home_team_name\", \"away_team_name\"])\n",
    "\n",
    "\n",
    "# compute VAEP-based team metrics for a single match\n",
    "def evaluate_team_metrics(game_id, home_name, away_name, model):\n",
    "    \"\"\"\n",
    "    Given a match ID and team names, computes various metrics\n",
    "    \"\"\"\n",
    "    # Get match info\n",
    "    match = games.loc[games[\"game_id\"] == game_id].iloc[0]\n",
    "    home_id, away_id = match[\"home_team_id\"], match[\"away_team_id\"]\n",
    "\n",
    "    # Load raw events for the game\n",
    "    events = sbl.events(game_id)\n",
    "\n",
    "    # Convert StatsBomb events to SPADL format and add action names\n",
    "    actions = spadl.add_names(spadl_sb.convert_to_actions(events, home_id))\n",
    "\n",
    "    # Prepare output DataFrame indexed by team IDs\n",
    "    df = pd.DataFrame(index=[home_id, away_id])\n",
    "\n",
    "    # predict VAEP values for each action\n",
    "    gamestates = feat.play_left_to_right(feat.gamestates(actions, nb_prev_actions=3), home_id)\n",
    "\n",
    "    # Build feature matrix using multiple encoders\n",
    "    X = pd.concat([f(gamestates) for f in [\n",
    "        feat.actiontype_onehot, feat.result_onehot, feat.bodypart_onehot, feat.startlocation,\n",
    "        feat.endlocation, feat.movement, feat.time\n",
    "    ]], axis=1)\n",
    "\n",
    "    # ensure all expected columns exist , fill missing ones with 0\n",
    "    for col in expected_columns:\n",
    "        if col not in X.columns:\n",
    "            X[col] = 0\n",
    "    X = X[expected_columns]\n",
    "\n",
    "    # Predict VAEP for each action\n",
    "    actions[\"vaep_pred\"] = model.predict(X)\n",
    "\n",
    "    # Events enrichements , adding basic info to each action\n",
    "    # time since previous action\n",
    "    actions[\"time_diff\"] = actions[\"time_seconds\"].diff().fillna(0)\n",
    "    # movement distance of the ball\n",
    "    actions[\"distance\"] = np.sqrt((actions['end_x'] - actions['start_x'])**2 + (actions['end_y'] - actions['start_y'])**2)\n",
    "\n",
    "     # VAEP metrics\n",
    "    df[\"VAEP_Passes\"] = actions[actions[\"type_name\"] == \"pass\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Crosses\"] = actions[actions[\"type_name\"].isin([\"cross\", \"freekick_crossed\", \"corner_crossed\"])].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Dribbles\"] = actions[actions[\"type_name\"] == \"dribble\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Shot\"] = actions[actions[\"type_name\"] == \"shot\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Clearance\"] = actions[actions[\"type_name\"] == \"clearance\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Interception\"] = actions[actions[\"type_name\"] == \"interception\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Foul\"] = actions[actions[\"type_name\"] == \"foul\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_Tackle\"] = actions[actions[\"type_name\"] == \"tackle\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_BadTouch\"] = actions[actions[\"type_name\"] == \"bad_touch\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "    df[\"VAEP_KeeperSave\"] = actions[actions[\"type_name\"] == \"keeper_save\"].groupby(\"team_id\")[\"vaep_pred\"].sum()\n",
    "\n",
    "\n",
    "    # Other metrics , traditional metrics and not VAEP based\n",
    "    passes = actions[actions['type_name'] == 'pass']\n",
    "    defensive_actions = actions[actions['type_name'].isin(['tackle', 'interception', 'clearance']) & (actions['start_x'] >= 40)]\n",
    "    ppda_n = passes.groupby('team_id').size()\n",
    "    ppda_d = defensive_actions.groupby('team_id').size()\n",
    "    df['PPDA'] = ppda_n / ppda_d\n",
    "\n",
    "    progressive_passes = passes.copy()\n",
    "    total_distance_pass = np.sqrt((progressive_passes['end_x'] - progressive_passes['start_x'])**2 + (progressive_passes['end_y'] - progressive_passes['start_y'])**2)\n",
    "    vertical_distance = progressive_passes['end_x'] - progressive_passes['start_x']\n",
    "    verticality_ratio = vertical_distance / total_distance_pass.replace(0, np.nan)\n",
    "    df['Verticality'] = progressive_passes.assign(ratio=verticality_ratio).groupby('team_id')['ratio'].mean()\n",
    "    df['ProgressivePasses'] = progressive_passes[progressive_passes['end_x'] - progressive_passes['start_x'] > 10].groupby('team_id').size()\n",
    "    df['BuildUpSpeed'] = actions.groupby('team_id')['distance'].sum() / actions.groupby('team_id')['time_diff'].sum()\n",
    "\n",
    "    # fill missing values with 0\n",
    "    df = df.fillna(0)\n",
    "    # replace team ids with team names\n",
    "    df.index = df.index.map(lambda x: home_name if x == home_id else away_name)\n",
    "    return df\n",
    "\n",
    "# store cumulative metrics for all teams\n",
    "team_vaep_metrics = {}\n",
    "\n",
    "# loop through each match\n",
    "for _, row in tqdm(matches_of_interest.iterrows(), total=len(matches_of_interest)):\n",
    "    game_id = row[\"game_id\"]\n",
    "    home_name = row[\"home_team_name\"]\n",
    "    away_name = row[\"away_team_name\"]\n",
    "\n",
    "    # get metrics for this match\n",
    "    df = evaluate_team_metrics(game_id, home_name, away_name, model)\n",
    "\n",
    "    # add metrics to each team (sum over matches)\n",
    "    for team in df.index:\n",
    "        if team not in team_vaep_metrics:\n",
    "            team_vaep_metrics[team] = df.loc[team]  # first time just add\n",
    "        else:\n",
    "            team_vaep_metrics[team] += df.loc[team] # otherwise sum up\n",
    "\n",
    "# convert dictionary to DataFrame for readability\n",
    "df_stocked = pd.DataFrame(team_vaep_metrics).T.fillna(0)\n",
    "print(\"Data available in df_stocked\")\n",
    "print(df_stocked)\n",
    "\n",
    "\n",
    "def apply_pca_transformation(df_stocked, n_components=None, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to create latent tactical style components\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\" PCA-BASED TACTICAL STYLE TRANSFORMATION\")\n",
    "    \n",
    "    # prepare data\n",
    "    X = df_stocked.copy()\n",
    "    # make sure to have only one team and no duplicates\n",
    "    X = X.loc[~X.index.duplicated(keep='first')]\n",
    "\n",
    "    # CORRELATION ANALYSIS\n",
    "    print(\"\\n CORRELATION ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    # find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    print(f\"Highly correlated pairs (>0.7): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"   {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "    \n",
    "    # STANDARDIZATION\n",
    "    print(\"\\n DATA STANDARDIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\" Data standardized (mean=0, std=1)\")\n",
    "    \n",
    "    # PCA APPLICATION\n",
    "    print(\"\\n PCA APPLICATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # apply PCA with all components first to analyze variance\n",
    "    pca_full = PCA()\n",
    "    X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "    \n",
    "    # calculate cumulative variance\n",
    "    added_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "    \n",
    "    # determine the number of components\n",
    "    if n_components is None:\n",
    "        n_components = np.argmax(added_variance >= variance_threshold) + 1\n",
    "        print(f\"Components needed for {variance_threshold*100}% variance: {n_components}\")\n",
    "    \n",
    "    # apply PCA with the chosen number of components\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Final PCA shape: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Cumulative variance explained: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "    \n",
    "    # component interpretation\n",
    "    print(\"\\n TACTICAL STYLE COMPONENTS INTERPRETATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # create component interpretation\n",
    "    components_df = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.columns\n",
    "    )\n",
    "    \n",
    "    # interpret each component\n",
    "    tactical_styles = {}\n",
    "    for i in range(n_components):\n",
    "        component_name = f'Style_{i+1}'\n",
    "        component_loadings = components_df[component_name].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\n {component_name} (explains {pca.explained_variance_ratio_[i]:.1%} variance):\")\n",
    "        \n",
    "        # top positive loadings\n",
    "        pos_loadings = components_df[component_name].sort_values(ascending=False).head(3)\n",
    "        print(\"   Top positive loadings:\")\n",
    "        for feat, loading in pos_loadings.items():\n",
    "            print(f\"      +{loading:.3f} {feat}\")\n",
    "        \n",
    "        # top negative loadings\n",
    "        neg_loadings = components_df[component_name].sort_values(ascending=True).head(3)\n",
    "        print(\"   Top negative loadings:\")\n",
    "        for feat, loading in neg_loadings.items():\n",
    "            print(f\"      {loading:.3f} {feat}\")\n",
    "        \n",
    "        # suggest a tactical interpretation\n",
    "        top_features = component_loadings.head(3).index.tolist()\n",
    "        tactical_styles[component_name] = {\n",
    "            'variance_explained': pca.explained_variance_ratio_[i],\n",
    "            'top_features': top_features\n",
    "        }\n",
    "    \n",
    "    # Create a PCA dataFrame for visibility and better understandings\n",
    "    pca_df = pd.DataFrame(\n",
    "        X_pca, \n",
    "        columns=[f'Style_{i+1}' for i in range(n_components)],\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'pca_df': pca_df,\n",
    "        'pca_model': pca,\n",
    "        'scaler': scaler,\n",
    "        'components_df': components_df,\n",
    "        'tactical_styles': tactical_styles,\n",
    "        'original_data': X,\n",
    "        'scaled_data': X_scaled,\n",
    "        'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "        'added_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "    }\n",
    "\n",
    "def cluster_pca_styles(pca_results, clustering_methods=None, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Apply clustering to PCA-transformed tactical styles\n",
    "    \"\"\"\n",
    "    # The 5 clustering algorithms\n",
    "    if clustering_methods is None:\n",
    "        clustering_methods = {\n",
    "            \"KMeans\": {\"n_clusters\": 9},\n",
    "            \"Agglomerative\": {\"n_clusters\": 9},\n",
    "            \"GMM\": {\"n_components\": 9},\n",
    "            \"Spectral\": {\"n_clusters\": 9},\n",
    "            \"Birch\": {\"n_clusters\": 6}\n",
    "        }\n",
    "    \n",
    "\n",
    "    # Extract the PCA-transformed feature matrix (scores) from results\n",
    "    # Get PCA scores as a NumPy array for clustering\n",
    "    pca_df = pca_results['pca_df']\n",
    "    X_pca = pca_df.values\n",
    "    \n",
    "    # standardize PCA components\n",
    "    scaler_pca = StandardScaler()\n",
    "    X_pca_scaled = scaler_pca.fit_transform(X_pca)\n",
    "\n",
    "\n",
    "    print(\"\\n OPTIMAL NUMBER OF CLUSTERS\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Test different numbers of clusters\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    # metrics for different clustering algorithms\n",
    "    metrics = {\n",
    "        'KMeans': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Agglomerative': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'GMM': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Birch': {'silhouette': [], 'calinski': [], 'davies': []},\n",
    "        'Spectral': {'silhouette': [], 'calinski': [], 'davies': []}\n",
    "    }\n",
    "\n",
    "    # Try different numbers of clusters for each algorithm and record quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    for n_clusters in cluster_range:\n",
    "        \n",
    "        # KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels_km = kmeans.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Agglomerative\n",
    "        agg = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        labels_agg = agg.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # GMM\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        labels_gmm = gmm.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Birch \n",
    "        birch = Birch(n_clusters=n_clusters)\n",
    "        labels_birch = birch.fit_predict(X_pca_scaled)\n",
    "        \n",
    "        # Spectral\n",
    "        try:\n",
    "            spectral = SpectralClustering(n_clusters=n_clusters, random_state=42, affinity='nearest_neighbors')\n",
    "            labels_spectral = spectral.fit_predict(X_pca_scaled)\n",
    "        except Exception as e:\n",
    "            print(f\"  Spectral clustering failed for {n_clusters} clusters: {e}\")\n",
    "            # créer des labels par défaut en cas d'échec\n",
    "            labels_spectral = np.zeros(len(X_pca_scaled), dtype=int)\n",
    "        \n",
    "        # calculate metrics \n",
    "        for name, labels in [('KMeans', labels_km), ('Agglomerative', labels_agg), \n",
    "                           ('GMM', labels_gmm), ('Birch', labels_birch), ('Spectral', labels_spectral)]:\n",
    "            if len(np.unique(labels)) > 1:  # Need at least 2 clusters for metrics (For 2D vizualisation)\n",
    "                try:\n",
    "                    metrics[name]['silhouette'].append(silhouette_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['calinski'].append(calinski_harabasz_score(X_pca_scaled, labels))\n",
    "                    metrics[name]['davies'].append(davies_bouldin_score(X_pca_scaled, labels))\n",
    "                except Exception as e:\n",
    "                    print(f\"   Error calculating metrics for {name} with {n_clusters} clusters: {e}\")\n",
    "                    metrics[name]['silhouette'].append(0)\n",
    "                    metrics[name]['calinski'].append(0)\n",
    "                    metrics[name]['davies'].append(float('inf'))\n",
    "            else:\n",
    "                metrics[name]['silhouette'].append(0)\n",
    "                metrics[name]['calinski'].append(0)\n",
    "                metrics[name]['davies'].append(float('inf'))\n",
    "\n",
    "    # print optimal number of clusters\n",
    "    print(\"Optimal number of clusters by metric:\")\n",
    "    for algorithm in metrics.keys():\n",
    "        if metrics[algorithm]['silhouette']:\n",
    "            try:\n",
    "                best_sil = cluster_range[np.argmax(metrics[algorithm]['silhouette'])]\n",
    "                best_cal = cluster_range[np.argmax(metrics[algorithm]['calinski'])]\n",
    "                best_dav = cluster_range[np.argmin(metrics[algorithm]['davies'])]\n",
    "                print(f\"   {algorithm:>12}: Silhouette={best_sil}, Calinski={best_cal}, Davies-Bouldin={best_dav}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   {algorithm:>12}: Error calculating optimal clusters - {e}\")\n",
    "\n",
    "    # Print the full score table per algorithm\n",
    "    print(\"\\n Full clustering scores by number of clusters:\")\n",
    "    for algorithm in metrics:\n",
    "        print(f\"\\n {algorithm}\")\n",
    "        print(\"Clusters | Silhouette | Calinski-Harabasz | Davies-Bouldin\")\n",
    "        for i, n in enumerate(cluster_range):\n",
    "            if i < len(metrics[algorithm]['silhouette']):\n",
    "                sil = metrics[algorithm]['silhouette'][i]\n",
    "                cal = metrics[algorithm]['calinski'][i]\n",
    "                dav = metrics[algorithm]['davies'][i]\n",
    "                print(f\"{n:>8} | {sil:>10.3f} | {cal:>18.2f} | {dav:>15.3f}\")\n",
    "    \n",
    "    clustering_results = {}\n",
    "\n",
    "    # Fit each clustering algorithm with its chosen parameters on the PCA data\n",
    "    # compute quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin)\n",
    "    # store the results and print the composition of each cluster.\n",
    "    for method_name, params in clustering_methods.items():\n",
    "        print(f\"\\n {method_name} Clustering\")\n",
    "        \n",
    "        try:\n",
    "            if method_name == \"KMeans\":\n",
    "                model = KMeans(random_state=42, n_init=10, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Agglomerative\":\n",
    "                model = AgglomerativeClustering(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"GMM\":\n",
    "                model = GaussianMixture(random_state=42, **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Spectral\":\n",
    "                model = SpectralClustering(random_state=42, affinity='nearest_neighbors', **params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "                \n",
    "            elif method_name == \"Birch\":  \n",
    "                model = Birch(**params)\n",
    "                labels = model.fit_predict(X_pca_scaled)\n",
    "            \n",
    "            # evaluate clustering quality\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                sil_score = silhouette_score(X_pca_scaled, labels)\n",
    "                cal_score = calinski_harabasz_score(X_pca_scaled, labels)\n",
    "                dav_score = davies_bouldin_score(X_pca_scaled, labels)\n",
    "                \n",
    "                print(f\"   Silhouette Score: {sil_score:.3f}\")\n",
    "                print(f\"   Calinski-Harabasz: {cal_score:.2f}\")\n",
    "                print(f\"   Davies-Bouldin: {dav_score:.3f}\")\n",
    "                \n",
    "                clustering_results[method_name] = {\n",
    "                    'labels': labels,\n",
    "                    'model': model,\n",
    "                    'silhouette': sil_score,\n",
    "                    'calinski': cal_score,\n",
    "                    'davies_bouldin': dav_score\n",
    "                }\n",
    "                \n",
    "                # Print cluster composition\n",
    "                print(f\"   Cluster composition:\")\n",
    "                for cluster_id in np.unique(labels):\n",
    "                    cluster_teams = pca_df.index[labels == cluster_id].tolist()\n",
    "                    print(f\"      Cluster {cluster_id}: {cluster_teams}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\" Error with {method_name}: {e}\")\n",
    "    \n",
    "    return clustering_results\n",
    "\n",
    "\n",
    "def visualize_pca_clusters(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Visualize clustering results on PCA space\n",
    "    \"\"\"\n",
    "    print(\"\\n CLUSTERING VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    #Extract PCA scores (teams and components) and variance ratios for labeling axes\n",
    "    pca_df = pca_results['pca_df']\n",
    "    explained_variance = pca_results['explained_variance_ratio']\n",
    "    \n",
    "    # create a visualization for each clustering method\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        sil_score = result['silhouette']\n",
    "        \n",
    "        # create plot dataframe\n",
    "        plot_df = pca_df.copy()\n",
    "        plot_df['Team'] = plot_df.index\n",
    "        plot_df['Cluster'] = labels.astype(str)\n",
    "        \n",
    "        # 2D visualization for first two components\n",
    "        if pca_df.shape[1] >= 2:\n",
    "            fig = px.scatter(\n",
    "                plot_df, x='Style_1', y='Style_2',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering on Tactical Styles',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})'},\n",
    "                width=1000, height=600\n",
    "            )\n",
    "            fig.update_traces(textposition='top center')\n",
    "            fig.show()\n",
    "        \n",
    "        # 3D visualization if we have at least 3 components\n",
    "        if pca_df.shape[1] >= 3:\n",
    "            fig = px.scatter_3d(\n",
    "                plot_df, x='Style_1', y='Style_2', z='Style_3',\n",
    "                color='Cluster', text='Team',\n",
    "                category_orders={\"Cluster\": sorted(plot_df[\"Cluster\"].unique(), key=lambda x: int(x))}, \n",
    "                title=f'{method_name} Clustering - 3D Tactical Space',\n",
    "                labels={'Style_1': f'Style 1 ({explained_variance[0]:.1%})',\n",
    "                       'Style_2': f'Style 2 ({explained_variance[1]:.1%})',\n",
    "                       'Style_3': f'Style 3 ({explained_variance[2]:.1%})'},\n",
    "                width=1000, height=700\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "def compute_global_discriminant_features(pca_results, clustering_results):\n",
    "    \"\"\"\n",
    "    Compute average F-ratio (feature importance) across all clustering methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n GLOBAL MOST DISCRIMINANT FEATURES (FOR ALL CLUSTERINGS)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Prepare a dictionary to store F-ratios per feature for each clustering method\n",
    "    original_data = pca_results['original_data']\n",
    "    global_f_ratios = {feature: [] for feature in original_data.columns}\n",
    "\n",
    "    # Loop over results from each clustering algorithm\n",
    "    for method_name, result in clustering_results.items():\n",
    "        labels = result['labels']\n",
    "        original_with_clusters = original_data.copy()\n",
    "        original_with_clusters['Cluster'] = labels\n",
    "        unique_clusters = np.unique(labels)\n",
    "\n",
    "        #Loop through every original metric (feature)\n",
    "        for feature in original_data.columns:\n",
    "            feature_values = original_with_clusters[feature].values\n",
    "            overall_mean = np.mean(feature_values)\n",
    "\n",
    "            between_ss = 0\n",
    "            within_ss = 0\n",
    "\n",
    "            # Loop through each cluster to accumulate between/within variance\n",
    "            for cluster_id in unique_clusters:\n",
    "                cluster_vals = original_with_clusters[original_with_clusters['Cluster'] == cluster_id][feature].values\n",
    "                cluster_mean = np.mean(cluster_vals)\n",
    "                between_ss += len(cluster_vals) * (cluster_mean - overall_mean) ** 2\n",
    "                within_ss += np.sum((cluster_vals - cluster_mean) ** 2)\n",
    "\n",
    "            # Compute the F-ratio: higher means the feature better separates clusters\n",
    "            f_ratio = between_ss / within_ss if within_ss > 0 else 0\n",
    "            # Save this F-ratio for the current feature and clustering method\n",
    "            global_f_ratios[feature].append(f_ratio)\n",
    "\n",
    "    # average F-ratios across algorithms\n",
    "    avg_f_ratios = [(feature, np.mean(f_vals)) for feature, f_vals in global_f_ratios.items()]\n",
    "    avg_f_ratios.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\" Averaged most discriminating features across clustering methods:\")\n",
    "    for i, (feature, avg_f) in enumerate(avg_f_ratios):\n",
    "        print(f\"   {i+1:2d}. {feature:<25} Avg F-ratio = {avg_f:.3f}\")\n",
    "\n",
    "    # main execution function\n",
    "def run_pca_tactical_analysis(df_stocked):\n",
    "    \"\"\"\n",
    "    Run a complete PCA-based tactical analysis\n",
    "    \"\"\"\n",
    "    # 1: Apply PCA transformation\n",
    "    pca_results = apply_pca_transformation(df_stocked, variance_threshold=0.85)\n",
    "    \n",
    "    # 2: Apply clustering to PCA components\n",
    "    clustering_results = cluster_pca_styles(pca_results, max_clusters=9)\n",
    "    \n",
    "    # 3: Visualize clustering results\n",
    "    visualize_pca_clusters(pca_results, clustering_results)\n",
    "\n",
    "    # 4: Compute global discriminant features across all clusterings\n",
    "    compute_global_discriminant_features(pca_results, clustering_results)\n",
    "\n",
    "    #Return results for further analysis\n",
    "    return {\n",
    "        'pca_results': pca_results,\n",
    "        'clustering_results': clustering_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Run main function\n",
    "results = run_pca_tactical_analysis(df_stocked)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# Additional functionalities if needed\n",
    "\n",
    "# save the scores per team based on average with colors in images\n",
    "\n",
    "# calculate average and categorize performance with 6 levels\n",
    "metric_averages = df_stocked.mean()\n",
    "performance = pd.DataFrame(index=df_stocked.index, columns=df_stocked.columns)\n",
    "\n",
    "# Assign performance ratings for each team and metric using league average ± standard deviations\n",
    "for col in df_stocked.columns:\n",
    "    avg = metric_averages[col]\n",
    "    std = df_stocked[col].std()\n",
    "    for team in df_stocked.index:\n",
    "        val = df_stocked.loc[team, col]\n",
    "        if val >= avg + 2*std:\n",
    "            cat = \"+++\"  # very good performance (2+ std above avg)\n",
    "        elif val >= avg + std:\n",
    "            cat = \"++\"   # good performance (1-2 std above avg)\n",
    "        elif val >= avg:\n",
    "            cat = \"+\"    # Above average performance\n",
    "        elif val <= avg - 2*std:\n",
    "            cat = \"---\"  # Very poor performance (2+ std below avg)\n",
    "        elif val <= avg - std:\n",
    "            cat = \"--\"   # Poor performance (1-2 std below avg)\n",
    "        else:\n",
    "            cat = \"-\"    # Below average performance\n",
    "        performance.loc[team, col] = cat\n",
    "\n",
    "# combine value and label\n",
    "df_display = df_stocked.round(2).astype(str) + \" (\" + performance + \")\"\n",
    "df_display.loc[\"League Average\"] = [f\"{metric_averages[col]:.2f} (avg)\" for col in df_stocked.columns]\n",
    "\n",
    "# save Horizontal Table ----------\n",
    "plt.figure(figsize=(len(df_display.columns) * 2.2, len(df_display) * 0.35))\n",
    "sns.set(font_scale=0.72)\n",
    "table = plt.table(cellText=df_display.values,\n",
    "                  rowLabels=df_display.index,\n",
    "                  colLabels=df_display.columns,\n",
    "                  loc='center',\n",
    "                  cellLoc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(6.5)\n",
    "table.scale(1.05, 1.08)\n",
    "\n",
    "# add colors based on performance categories (6 levels)\n",
    "for i in range(len(df_display)):\n",
    "    for j in range(len(df_display.columns)):\n",
    "        cell_text = df_display.iloc[i, j]\n",
    "        if \"(+++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#006400')  # Very dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(++)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#2E8B57')  # Dark green\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(+)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#90EE90')  # Light green\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(---)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#8B0000')  # Very dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(--)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#CD5C5C')  # Dark red\n",
    "            table[(i+1, j)].set_text_props(weight='bold', color='white')\n",
    "        elif \"(-)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#FFB6C1')  # Light red\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "        elif \"(avg)\" in cell_text:\n",
    "            table[(i+1, j)].set_facecolor('#D3D3D3')  # Light gray\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Team Tactical Metrics - Horizontal View', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"team_tactical_metrics_performance_table_PremierLeague_1516_VAEP+OTHER.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "print(\"\\nLegend:\")\n",
    "print(\"+++ (Very Dark Green): Exceptional - Above average + 2 standard deviations\")\n",
    "print(\"++ (Dark Green): Very Good - Above average + 1 standard deviation\")\n",
    "print(\"+ (Light Green): Good - Above average\")\n",
    "print(\"- (Light Red): Below average\")\n",
    "print(\"-- (Dark Red): Poor - Below average - 1 standard deviation\")\n",
    "print(\"--- (Very Dark Red): Very Poor - Below average - 2 standard deviations\")\n",
    "print(\"avg (Gray): League average\")\n",
    "\n",
    "# Display the categorized data \n",
    "print(\"\\n Performance Categories:\")\n",
    "print(performance)\n",
    "\n",
    "# Display average scores per metric\n",
    "print(\"\\n Average Scores per Metric:\")\n",
    "print(metric_averages.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b54f1-444d-426e-8f4e-2260c9c9a093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (soccer)",
   "language": "python",
   "name": "soccer_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
